{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: 7.1 Complex Eigen Values and Linear Dynamical Systems\n",
    "subject: Dynamics\n",
    "subtitle: \n",
    "short_title: 7.1 Complex Eigen Values and Linear Dynamical Systems\n",
    "authors:\n",
    "  - name: Nikolai Matni\n",
    "    affiliations:\n",
    "      - Dept. of Electrical and Systems Engineering\n",
    "      - University of Pennsylvania\n",
    "    email: nmatni@seas.upenn.edu\n",
    "license: CC-BY-4.0\n",
    "keywords: linear systems, \n",
    "math:\n",
    "  '\\vv': '\\mathbf{#1}'\n",
    "  '\\bm': '\\begin{bmatrix}'\n",
    "  '\\em': '\\end{bmatrix}'\n",
    "  '\\R': '\\mathbb{R}'\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/nikolaimatni/ese-2030/HEAD?labpath=/06_Ch_7_Dynamics/081-complex_eig_LDS.ipynb)\n",
    "\n",
    "{doc}`Lecture notes <../lecture_notes/Lecture 13 - Complex and Repeated Eigenvalues Revisited, Jordan Blocks, Matrix Exponential.pdf>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading\n",
    "\n",
    "Material related to this page, as well as additional exercises, can be found in ALA .\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this page, you should know:\n",
    "- d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex Eigenvalues and Linear Dynamical Systems\n",
    "\n",
    "Let's apply our solution method for linear dynamical systems to $\\dot{\\vv x} = A \\vv x$ with\n",
    "$A = \\begin{bmatrix} 0 & -1 \\\\ 1 & 0 \\end{bmatrix}$ that we saw in the previous lecture. Recall that $A$ has eigenvalue/eigenvector pairs:\n",
    "\n",
    "\\begin{equation}\n",
    "\\label{eig_vals}\n",
    "\\lambda_1 = i, \\ \\vv v_1 = \\begin{bmatrix} 1 \\\\ -i \\end{bmatrix} \\quad \\text{and} \\quad \\lambda_2 = -i, \\vv v_2 = \\begin{bmatrix} 1 \\\\ i \\end{bmatrix}.\n",
    "\\end{equation}\n",
    "\n",
    "Even though [these](#eig_vals) have complex entries, we can still use the approach from last class. We write the solution to $\\dot{\\vv x} = A\\vv x$ as\n",
    "\n",
    "\\begin{equation}\n",
    "\\label{sol}\n",
    "\\vv x(t) = c_1e^{\\lambda_1 t}\\vv v_1 + c_2e^{\\lambda_2t}\\vv v_2 = c_1e^{it}\\begin{bmatrix} 1 \\\\ -i \\end{bmatrix} + c_2e^{-it}\\begin{bmatrix} 1 \\\\ i \\end{bmatrix}, \\quad (\\text{SOL})\n",
    "\\end{equation}\n",
    "\n",
    "i.e., $\\vv x(t)$ is a linear combination of the two solutions\n",
    "\n",
    "\\begin{equation}\n",
    "\\label{base}\n",
    "\\vv x_1(t) = c_1e^{it}\\begin{bmatrix} 1 \\\\ -i \\end{bmatrix} \\quad \\text{and} \\quad \\vv x_2(t) = c_2e^{-it}\\begin{bmatrix} 1 \\\\ i \\end{bmatrix}. \\quad (\\text{BASE})\n",
    "\\end{equation}\n",
    "\n",
    "and then solve for $c_1$ and $c_2$ to ensure compatibility with the initial condition $\\vv x(0)$. In general $c_1$ and $c_2$ will also be complex numbers, and $\\vv x(t)$ will take complex values. This is mathematically correct, and indeed one can study dynamical systems evolving over complex numbers.\n",
    "\n",
    "However, in this class, and in most engineering applications, we are interested in _real solutions to $\\dot{\\vv x} = A\\vv x$_. If we know want real solutions, it might make sense to try to find different \"base\" solutions than $\\vv x_1(t)$ and $\\vv x_2(t)$ that still span all possible solutions to $\\dot{\\vv x} = A\\vv x$. Our key tool for accomplishing this is [Euler's formula](https://en.wikipedia.org/wiki/Euler%27s_formula), which states that for any $t \\in \\mathbb{R}$,\n",
    "\n",
    "\\begin{equation}\n",
    "\\label{eul}\n",
    "e^{it} = \\cos t + i \\sin t \\quad (\\text{EUL}).\n",
    "\\end{equation}\n",
    "\n",
    "We apply ([EUL](#eul)) to ([BASE](#base)), and obtain (after simplifying):\n",
    "\n",
    "$$\n",
    "\\vv x_1(t) = e^{it}\\begin{bmatrix} 1 \\\\ -i \\end{bmatrix} = \\begin{bmatrix} \\cos t \\\\ -\\sin t \\end{bmatrix} + i\\begin{bmatrix} \\sin t \\\\ \\cos t \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$ \n",
    "\\vv x_2(t) = e^{-it}\\begin{bmatrix} 1 \\\\ i \\end{bmatrix} = \\begin{bmatrix} \\cos t \\\\ \\sin t \\end{bmatrix} - i\\begin{bmatrix} \\sin t \\\\ \\cos t \\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "We've made some progress, in that $\\vv x_1(t)$ and $\\vv x_2(t)$ are now in the \"standard\" complex number form $a+ib$, and that $\\vv x_1(t) = \\overline{\\vv x_2(t)}$, i.e. they are clearly complex conjugates of each other. We use this observation strategically to define two new \"base\" solutions:\n",
    "\n",
    "\\[\\hat{x}_1(t) = \\frac{1}{2}(x_1(t) + x_2(t)) = \\frac{1}{2}(x_1(t) + \\overline{x_1(t)}) = \\begin{bmatrix} \\cos t \\\\ \\sin t \\end{bmatrix} (= \\text{Re}\\{x_1(t)\\})\\]\n",
    "\n",
    "\\[\\hat{x}_2(t) = \\frac{1}{2i}(x_1(t) - x_2(t)) = \\frac{1}{2i}(x_1(t) - \\overline{x_1(t)}) = \\begin{bmatrix} \\sin t \\\\ -\\cos t \\end{bmatrix} (= \\text{Im}\\{x_1(t)\\})\\]\n",
    "\n",
    "We note that since $\\hat{x}_1(t)$ and $\\hat{x}_2(t)$ are linear combinations of $x_1(t)$ and $x_2(t)$, they are valid solutions to $\\dot{x} = Ax$. Furthermore, since $\\hat{x}_1(t)$ and $\\hat{x}_2(t)$ are linearly independent (i.e., $c_1\\hat{x}_1(t) + c_2\\hat{x}_2(t) = 0$ for all $t \\Rightarrow c_1 = c_2 = 0$), they form a basis for the solution set to $\\dot{x} = Ax$. Therefore, we can rewrite (SOL) as\n",
    "\n",
    "\\[x(t) = c_1\\begin{bmatrix} \\cos t \\\\ \\sin t \\end{bmatrix} + c_2\\begin{bmatrix} \\sin t \\\\ -\\cos t \\end{bmatrix},\\]\n",
    "\n",
    "and then solve for $c_1$ and $c_2$ using $x(0)$. If $c_1, c_2 \\in \\mathbb{R}^2$, i.e., if the initial condition $x(0)$ is real, then $c_1$ and $c_2$ will be too. For example, suppose $x(0) = \\begin{bmatrix} a \\\\ b \\end{bmatrix}$, with $a,b \\in \\mathbb{R}$. Then:\n",
    "\n",
    "\\[x(0) = c_1\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} + c_2\\begin{bmatrix} 0 \\\\ -1 \\end{bmatrix} = \\begin{bmatrix} c_1 \\\\ -c_2 \\end{bmatrix} = \\begin{bmatrix} a \\\\ b \\end{bmatrix} \\Rightarrow c_1 = a, c_2 = -b,\\]\n",
    "\n",
    "and $x(t) = \\begin{bmatrix} a\\cos t - b\\sin t \\\\ a\\sin t + b\\cos t \\end{bmatrix} = \\begin{bmatrix} \\cos t & -\\sin t \\\\ \\sin t & \\cos t \\end{bmatrix}\\begin{bmatrix} a \\\\ b \\end{bmatrix} = R(t)x(0)$,\n",
    "\n",
    "i.e., the solution $x(t)$ corresponds to the initial condition $x(0)$ being rotated in a counterclockwise direction at a frequency of 1 rad/s.\n",
    "\n",
    "The key steps in the above procedure were:\n",
    "\n",
    "1) Apply Euler's formula to rewrite the base solutions as\n",
    "   $x_1(t) = \\text{Re}\\{x_1(t)\\} + i\\text{Im}\\{x_1(t)\\}, x_2(t) = \\overline{x_1(t)} = \\text{Re}\\{x_1(t)\\} - i\\text{Im}\\{x_1(t)\\}$\n",
    "\n",
    "2) Define new base solutions by setting:\n",
    "   $\\hat{x}_1(t) = \\text{Re}\\{x_1(t)\\}$ and $\\hat{x}_2(t) = \\text{Im}\\{x_2(t)\\}$\n",
    "\n",
    "It turns out that this approach is completely general, and can be applied whenever you encounter complex eigenvalue/vectors (which always appear as complex conjugate pairs).\n",
    "\n",
    "Example: Consider the linear dynamical system $\\dot{x} = Ax$, where\n",
    "\n",
    "\\[A = \\begin{bmatrix} 1 & 2 & 0 \\\\ 0 & 1 & -2 \\\\ 2 & 2 & -1 \\end{bmatrix} \\quad \\text{and} \\quad x(0) = \\begin{bmatrix} 2 \\\\ -1 \\\\ -2 \\end{bmatrix}.\\]\n",
    "\n",
    "Using the formula for the determinant of a 3x3 matrix (you don't need to memorize this!), we can compute the following eigenvalue/vector pairs:\n",
    "\n",
    "\\[\\begin{aligned}\n",
    "\\lambda_1 &= -2, & v_1 &= \\begin{bmatrix} -1 \\\\ 1 \\\\ 1 \\end{bmatrix} \\\\\n",
    "\\lambda_2 &= 1 + 2i, & v_2 &= \\begin{bmatrix} 1 \\\\ i \\\\ 1 \\end{bmatrix} \\\\\n",
    "\\lambda_3 &= 1 - 2i, & v_3 &= \\begin{bmatrix} 1 \\\\ -i \\\\ 1 \\end{bmatrix}\n",
    "\\end{aligned}\\]\n",
    "\n",
    "and obtain the corresponding eigensolutions:\n",
    "\n",
    "\\[x_1(t) = e^{-t}\\begin{bmatrix} -1 \\\\ 1 \\\\ 1 \\end{bmatrix}, \\quad x_2(t) = e^{(1+2i)t}\\begin{bmatrix} 1 \\\\ i \\\\ 1 \\end{bmatrix}, \\quad x_3(t) = e^{(1-2i)t}\\begin{bmatrix} 1 \\\\ -i \\\\ 1 \\end{bmatrix}.\\]\n",
    "\n",
    "Let's apply Euler's formula to $x_2(t)$ (remember that $e^{(1+2i)t} = e^t e^{2it}$):\n",
    "\n",
    "\\begin{align*}\n",
    "x_2(t) &= e^{(1+2i)t}\\begin{bmatrix} 1 \\\\ i \\\\ 1 \\end{bmatrix} = e^t(\\cos 2t + i\\sin 2t)\\begin{bmatrix} 1 \\\\ i \\\\ 1 \\end{bmatrix} \\\\\n",
    "&= \\begin{bmatrix} e^t\\cos 2t \\\\ -e^t\\sin 2t \\\\ e^t\\cos 2t \\end{bmatrix} + i\\begin{bmatrix} e^t\\sin 2t \\\\ e^t\\cos 2t \\\\ e^t\\sin 2t \\end{bmatrix}.\n",
    "\\end{align*}\n",
    "\n",
    "This means another set of real eigensolutions to $\\dot{x} = Ax$ is\n",
    "\n",
    "\\[x_1(t) = e^{-t}\\begin{bmatrix} -1 \\\\ 1 \\\\ 1 \\end{bmatrix}, \\quad \\hat{x}_2(t) = \\text{Re}\\{x_2(t)\\} = e^t\\begin{bmatrix} \\cos 2t \\\\ -\\sin 2t \\\\ \\cos 2t \\end{bmatrix},\\]\n",
    "\n",
    "\\[\\hat{x}_3(t) = \\text{Im}\\{x_2(t)\\} = e^t\\begin{bmatrix} \\sin 2t \\\\ \\cos 2t \\\\ \\sin 2t \\end{bmatrix},\\]\n",
    "\n",
    "and a general solution can be written as\n",
    "\n",
    "\\[x(t) = c_1x_1(t) + c_2\\hat{x}_2(t) + c_3\\hat{x}_3(t) = \\begin{bmatrix} -c_1e^{-t} + c_2e^t\\cos 2t + c_3e^t\\sin 2t \\\\ c_1e^{-t} - c_2e^t\\sin 2t + c_3e^t\\cos 2t \\\\ c_1e^{-t} + c_2e^t\\cos 2t + c_3e^t\\sin 2t \\end{bmatrix}\\]\n",
    "\n",
    "\n",
    "We compute our constants $c_1, c_2, c_3$ by solving\n",
    "\\[\n",
    "\\mathbf{X}(0) = \\begin{bmatrix}\n",
    "-c_1 + c_2 \\\\\n",
    "c_1 + c_3 \\\\\n",
    "c_1 + c_2\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "2 \\\\\n",
    "-1 \\\\\n",
    "-2\n",
    "\\end{bmatrix} \\Rightarrow c_1 = -2, \\quad c_2 = 0, \\quad c_3 = 1\n",
    "\\]\n",
    "\n",
    "thus obtaining the specific solution to our original initial value problem as:\n",
    "\\[\n",
    "\\mathbf{X}(t) = \\begin{bmatrix}\n",
    "x_1(t) \\\\\n",
    "x_2(t) \\\\\n",
    "x_3(t)\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "2e^t + e^t\\sin 2t \\\\\n",
    "-2e^t + e^t\\cos 2t \\\\\n",
    "-2e^t + e^t\\sin 2t\n",
    "\\end{bmatrix}.\n",
    "\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\textbf{Repeated Eigenvalues, Jordan Forms, and Linear Dynamical Systems}\n",
    "\n",
    "Let's revisit the matrix $A = \\begin{bmatrix} 2 & 1 \\\\ 0 & 2 \\end{bmatrix}$ we saw last class. This matrix has an eigenvalue $\\lambda = 2$ of algebraic multiplicity 2 ($\\det(A-\\lambda I) = (2-\\lambda)^2 = 0$ $\\Rightarrow \\lambda_1 = \\lambda_2 = 2$) but geometric multiplicity 1, i.e., only one linearly independent eigenvector\n",
    "\\[\n",
    "\\mathbf{v}_1 = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix},\n",
    "\\]\n",
    "\n",
    "exists. How can we solve $\\dot{\\mathbf{X}} = A\\mathbf{X}$ in this case? Taking the approach that we've seen so far, we would write a candidate solution as\n",
    "\\[\n",
    "\\mathbf{X}(t) = c_1 e^{2t} \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}.\n",
    "\\]\n",
    "\n",
    "But this won't work! What if $\\mathbf{X}(0) = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$? There is no $c_1 \\in \\mathbb{R}$ such that $\\mathbf{X}(0) = \\begin{bmatrix} c_1 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$. Does this mean no solution to $\\dot{\\mathbf{X}} = A\\mathbf{X}$ exists? This would be deeply unsettling! The issue here is that we are \"missing\" an eigenvector. To remedy this, we'll introduce the idea of a \\textit{generalized eigenvector}. We will only consider 2$\\times$2 matrices, in which case a generalized eigenvector $\\mathbf{v}_2$ for an eigenvalue $\\lambda$ with eigenvector $\\mathbf{v}_1$ is given by the solution to the linear system:\n",
    "\n",
    "\\[\n",
    "(A - \\lambda I)\\mathbf{v}_2 = \\mathbf{v}_1. \\quad (*)\n",
    "\\]\n",
    "\n",
    "For our example, we compute $\\mathbf{v}_2$ by solving:\n",
    "\n",
    "\\begin{align*}\n",
    "\\left(\\begin{bmatrix}\n",
    "2 & 1 \\\\\n",
    "0 & 2\n",
    "\\end{bmatrix} - 2\\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix}\\right)\\begin{bmatrix}\n",
    "v_{21} \\\\\n",
    "v_{22}\n",
    "\\end{bmatrix} &= \\begin{bmatrix}\n",
    "0 & 1 \\\\\n",
    "0 & 0\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "v_{21} \\\\\n",
    "v_{22}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "v_{22} \\\\\n",
    "0\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "1 \\\\\n",
    "0\n",
    "\\end{bmatrix} = \\mathbf{v}_1 \\\\[10pt]\n",
    "&\\Rightarrow v_{22} = 1 \\text{ and } v_{21} \\text{ is free. We set } v_{21} = 0 \\text{ and find} \\\\[5pt]\n",
    "&\\mathbf{v}_2 = \\begin{bmatrix}\n",
    "0 \\\\\n",
    "1\n",
    "\\end{bmatrix} \\text{ (any choice for } v_{21} \\text{ would work, this is just a convenient choice).}\n",
    "\\end{align*}\n",
    "\n",
    "Now, how can we construct a solution using $\\mathbf{v}_2$? If we try the strategy we used for eigenvalue/vector pairs, things do not quite work out:\n",
    "\n",
    "If $\\mathbf{X}(t) = e^{2t}\\mathbf{v}_2$ then $\\dot{\\mathbf{X}}(t) = 2e^{2t}\\mathbf{v}_2 = 2\\mathbf{X}$\n",
    "\n",
    "but $A\\mathbf{X}(t) = A(e^{2t}\\mathbf{v}_2) = e^{2t}(2\\mathbf{v}_2 + \\mathbf{v}_1) = 2\\mathbf{X} + \\mathbf{v}_1e^{2t}$,\n",
    "\n",
    "where we used the fact that the generalized eigenvector $\\mathbf{v}_2$ satisfies\n",
    "\n",
    "$A\\mathbf{v}_2 = \\lambda\\mathbf{v}_2 + \\mathbf{v}_1$,\n",
    "\n",
    "which is obtained by rearranging $(*)$. So we'll have to try something else. Let's see if\n",
    "\n",
    "$\\mathbf{X}(t) = e^{2t}\\mathbf{v}_2 + te^{2t}\\mathbf{v}_1$\n",
    "\n",
    "does better. This guess is made because we need to find a way to have $e^{2t}\\mathbf{v}_1$ appear in $\\dot{\\mathbf{X}}$.\n",
    "\n",
    "First we compute $\\dot{\\mathbf{X}} = 2e^{2t}\\mathbf{v}_2 + e^{2t}\\mathbf{v}_1 + 2te^{2t}\\mathbf{v}_1$\n",
    "                            $= 2(e^{2t}\\mathbf{v}_2 + te^{2t}\\mathbf{v}_1) + e^{2t}\\mathbf{v}_1$\n",
    "                            $= 2\\mathbf{X} + e^{2t}\\mathbf{v}_1$\n",
    "\n",
    "This looks promising! Now let's check\n",
    "\n",
    "\\begin{align*}\n",
    "A\\mathbf{X}(t) &= A(e^{2t}\\mathbf{v}_2 + te^{2t}\\mathbf{v}_1) = 2e^{2t}\\mathbf{v}_2 + e^{2t}\\mathbf{v}_1 + 2te^{2t}\\mathbf{v}_1 \\\\\n",
    "&= 2(e^{2t}\\mathbf{v}_2 + te^{2t}\\mathbf{v}_1) + e^{2t}\\mathbf{v}_1 \\\\\n",
    "&= 2\\mathbf{X} + e^{2t}\\mathbf{v}_1.\n",
    "\\end{align*}\n",
    "\n",
    "Success! We therefore can write solutions to our initial value problem as linear combinations of\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbf{y}_1(t) &= e^{2t}\\mathbf{v}_1 \\quad \\text{and} \\quad \\mathbf{y}_2(t) = e^{2t}\\mathbf{v}_2 + te^{2t}\\mathbf{v}_1, \\\\\n",
    "\\text{i.e.,} \\quad \\mathbf{X}(t) &= (c_1 + c_2t)e^{2t}\\mathbf{v}_1 + c_2e^{2t}\\mathbf{v}_2.\n",
    "\\end{align*}\n",
    "\n",
    "Let's check if we can find $c_1$ and $c_2$ so that $\\mathbf{X}(0) = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$:\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbf{X}(0) = c_1\\mathbf{v}_1 + c_2\\mathbf{v}_2 = \\begin{bmatrix} c_1 \\\\ c_2 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} \\Rightarrow c_1 = 0, \\, c_2 = 1\n",
    "\\end{align*}\n",
    "\n",
    "and $\\mathbf{X}(t) = \\begin{bmatrix} te^{2t} \\\\ e^{2t} \\end{bmatrix}$ is the solution to our initial value problem.\n",
    "\n",
    "\\textbf{2$\\times$2 Jordan Blocks}\n",
    "\n",
    "In the complete matrix setting, we saw that we could diagonalize the matrix $A$ using a similarity transformation defined by the eigenvectors of $A$, i.e., for $V = [\\mathbf{v}_1 \\, \\mathbf{v}_2 \\, \\ldots \\, \\mathbf{v}_n]$, we have that\n",
    "\n",
    "\\[\n",
    "A = V^{-1}\\Lambda V, \\text{ or equivalently, } A = V\\Lambda V^{-1}, \\quad \\Lambda = \\text{diag}(\\lambda_1, \\lambda_2, \\ldots, \\lambda_n).\n",
    "\\]\n",
    "\n",
    "We saw that this was very useful when solving systems of linear equations.\n",
    "\n",
    "In the case of incomplete matrices, similarity transformations defined in terms of generalized eigenvectors and Jordan blocks play an analogous role.\n",
    "\n",
    "For example, consider the matrix $A = \\begin{bmatrix} 1 & 1 \\\\ -1 & 3 \\end{bmatrix}$. This matrix has a repeated eigenvalue at $\\lambda = 2$, and one eigenvector $\\mathbf{v}_1 = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$. We therefore compute the generalized eigenvector by solving $(A-\\lambda I)\\mathbf{v}_2 = \\mathbf{v}_1$:\n",
    "\n",
    "\\[\n",
    "\\begin{bmatrix} -1 & 1 \\\\ -1 & 1 \\end{bmatrix}\\begin{bmatrix} v_{21} \\\\ v_{22} \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} \\Rightarrow -v_{21} + v_{22} = 1\n",
    "\\]\n",
    "\n",
    "One solution is $\\mathbf{v}_2 = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$. We construct our similarity transformation as before, and set $V = [\\mathbf{v}_1 \\, \\mathbf{v}_2] = \\begin{bmatrix} 1 & 0 \\\\ 1 & 1 \\end{bmatrix}$, and compute $V^{-1} = \\begin{bmatrix} 1 & 0 \\\\ -1 & 1 \\end{bmatrix}$\n",
    "\n",
    "Let's see what happens if we compute $V^{-1}AV$. In the complete case,\n",
    "\n",
    "This would give us a diagonal matrix. In this case, we get\n",
    "\n",
    "\\[\n",
    "\\begin{bmatrix} 1 & 0 \\\\ -1 & 1 \\end{bmatrix}\\begin{bmatrix} 1 & 1 \\\\ -1 & 3 \\end{bmatrix}\\begin{bmatrix} 1 & 0 \\\\ 1 & 1 \\end{bmatrix} = \\begin{bmatrix} 2 & 1 \\\\ 0 & 2 \\end{bmatrix},\n",
    "\\]\n",
    "\n",
    "which we'll recognize as our previous example! It turns out that all 2x2 matrices with $\\lambda=2$ having algebraic multiplicity 2 and geometric multiplicity 1 are similar to the Jordan Block\n",
    "\n",
    "\\[\n",
    "J = \\begin{bmatrix} 2 & 1 \\\\ 0 & 2 \\end{bmatrix},\n",
    "\\]\n",
    "\n",
    "and this similarity transformation is defined by $V = [\\mathbf{v}_1 \\, \\mathbf{v}_2]$ composed of the eigenvector $\\mathbf{v}_1$ and generalized eigenvector $\\mathbf{v}_2$ of the original matrix.\n",
    "\n",
    "We can generalize this idea to any 2x2 matrix with only one eigenvector:\n",
    "\n",
    "\\textbf{Theorem:} Let $A \\in \\mathbb{R}^{2\\times2}$ have eigenvalue $\\lambda$ with algebraic multiplicity 2 and geometric multiplicity 1. Let $\\mathbf{v}_1$ and $\\mathbf{v}_2$ satisfy\n",
    "\n",
    "\\[\n",
    "(A-\\lambda I)\\mathbf{v}_1 = \\mathbf{0} \\quad \\text{and} \\quad (A-\\lambda I)\\mathbf{v}_2 = \\mathbf{v}_1.\n",
    "\\]\n",
    "\n",
    "Then $A = VJ_\\lambda V^{-1}$, where $V = [\\mathbf{v}_1 \\, \\mathbf{v}_2]$ and $J_\\lambda$ is the Jordan Block\n",
    "\n",
    "\\[\n",
    "J_\\lambda = \\begin{bmatrix} \\lambda & 1 \\\\ 0 & \\lambda \\end{bmatrix}\n",
    "\\]\n",
    "\n",
    "Using this theorem, we can conclude, much in the same way we did for diagonalizable A, that if $A = VJ_\\lambda V^{-1}$, then\n",
    "\n",
    "\\[\n",
    "\\mathbf{X}(t) = (c_1 + c_2t)e^{\\lambda t}\\mathbf{v}_1 + c_2e^{\\lambda t}\\mathbf{v}_2\n",
    "\\]\n",
    "\n",
    "is a general solution to $\\dot{\\mathbf{X}} = A\\mathbf{X}$.\n",
    "\n",
    "\\textbf{NOTE:} This is a very specific instantiation of the Jordan Canonical Form of a matrix. You will learn more about the Jordan Canonical Form and its implications on differential equations in ESE 2100. For those interested in the fully general theorem statement, see ALA 3.6, Theorem 3.51."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/nikolaimatni/ese-2030/HEAD?labpath=/06_Ch_7_Dynamics/081-complex_eig_LDS.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
