{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Distance and Nearest Neighbors\n",
    "subject: Inner Products and Norms\n",
    "subtitle: Measuring how close two vectors are\n",
    "short_title: Distance and Nearest Neighbors\n",
    "authors:\n",
    "  - name: Nikolai Matni\n",
    "    affiliations:\n",
    "      - Dept. of Electrical and Systems Engineering\n",
    "      - University of Pennsylvania\n",
    "    email: nmatni@seas.upenn.edu\n",
    "license: CC-BY-4.0\n",
    "keywords: Distance, Nearest Neighbors\n",
    "math:\n",
    "  '\\vv': '\\mathbf{#1}'\n",
    "  '\\bm': '\\begin{bmatrix}'\n",
    "  '\\em': '\\end{bmatrix}'\n",
    "  '\\R': '\\mathbb{R}'\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading\n",
    "\n",
    "Material related to this page, as well as additional exercises, can be found in VMLS 3.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "By the end of this page, you should know:\n",
    "- What is the Euclidean distance between two vectors?\n",
    "- What are the properties of a general distance function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Euclidean Distance\n",
    "\n",
    "A distance function, or metric, describes how far apart 2 points are.\n",
    "\n",
    "A familiar starting point for our study of distances will be the Euclidean distance, which is closely related to the Euclidean norm on $\\mathbb R^n$:\n",
    "\n",
    ":::{prf:definition} The Euclidean Distance\n",
    ":label: euclidean_distance_defn\n",
    "\n",
    "For vectors $\\vv u, \\vv v \\in \\mathbb{R}^n$, the Euclidean distance is defined as the Euclidean norm of their difference $\\vv u - \\vv v$. In other words,\n",
    "\n",
    "\\begin{align*}\n",
    "    \\text{dist}(\\vv u, \\vv v) = \\| \\vv u - \\vv v\\| = \\sqrt{\\langle \\vv u - \\vv v, \\vv u - \\vv v \\rangle}\n",
    "\\end{align*}\n",
    ":::\n",
    "\n",
    "Note that this is measuring the length of the arrow drawn from point $\\vv x$ to point $\\vv y$:\n",
    "\n",
    ":::{figure}../figures/04-euc_dist.png\n",
    ":label:Euclidean distance\n",
    ":alt: Euclidean distance bewteen 2 vectors $\\vv x$ and $\\vv y$\n",
    ":width: 200px\n",
    ":align: center\n",
    ":::\n",
    "\n",
    "````{exercise}  Euclidean distance\n",
    ":label: distance-ex1\n",
    "\n",
    "Find the Euclidean distance between $\\bm 1\\\\ 2 \\em$ and $\\bm 3 \\\\ 4 \\em$.\n",
    "\n",
    "```{solution} distance-ex1\n",
    ":class: dropdown\n",
    "\n",
    "We have\n",
    "\n",
    "\\begin{align*}\n",
    "    \\text{dist}\\left(\\bm 1\\\\ 2 \\em, \\bm 3\\\\ 4 \\em\\right) = \\left\\| \\bm 1\\\\ 2 \\em - \\bm 3\\\\ 4 \\em \\right\\| = \\sqrt{ (1 - 3)^2 + (2 - 4)^2} =\\boxed{2\\sqrt 2}\n",
    "\\end{align*}\n",
    "\n",
    "```\n",
    "````\n",
    "\n",
    "# General Distances\n",
    "\n",
    "In this course, we will only work with the Euclidean distance. However, given any vector space with a general norm (i.e., $\\mathbb{R}^n$ with the Euclidean norm), we may construct a distance function as the norm of their difference. This leads us to a more general notion of distances:\n",
    "\n",
    ":::{prf:definition} General Distances\n",
    ":label: general_distance_defn\n",
    "\n",
    "For a set $S$, a function $d : S \\times S \\to \\mathbb R$ is a distance function, or metric, if it satisfies the following:\n",
    "\n",
    "1. **Symmetry.** For all $x, y \\in S$,\n",
    "\n",
    "\\begin{align*}\n",
    "    d(x, y) = d(y, x)\n",
    "\\end{align*}\n",
    "\n",
    "2. **Positivity.** For all $x, y \\in S$, \n",
    "\n",
    "\\begin{align*}\n",
    "    d(x, y) \\geq 0\n",
    "\\end{align*}\n",
    "and $d(x, y) = 0$ if and only if $x = y$.\n",
    "\n",
    "3. **Triangular Inequality.** For all $x, y, z \\in S$,\n",
    "\n",
    "\\begin{align*}\n",
    "    d(x, z) \\leq d(x, y) + d(y, z)\n",
    "\\end{align*}\n",
    "\n",
    ":::\n",
    "\n",
    "Try to convince yourself why the [Euclidean distance](#euclidean_distance_defn) fits this definition. \n",
    "\n",
    "When the distance $\\| \\vv x - \\vv y \\|$ between two vectors $\\vv x, \\vv y \\in V$ is small, we say they are \"close.\" If the distance between $\\| \\vv x - \\vv y \\|$ is large, we say they are \"far.\" What constitutes close or far is typically application dependent.\n",
    "\n",
    "Note that one vector space can admit many distance functions. From here on, unless otherwise mentioned, we will only be considering the [Euclidean distance](#euclidean_distance_defn).\n",
    "\n",
    ":::{prf:example} Matrix norms and their induced distances\n",
    ":label:distance-matrix_norm_ex\n",
    "\n",
    "Let $M \\in \\mathbb{R}^{n \\times n}$ be a symmetric square matrix such that $x^T M x > 0$ for all nonzero $x\\in \\mathbb{R}^n$. Such a matrix is called *positive definite*; some equivalent definitions of positive definite matrices are symmetric matrices which may be decomposed as $A^TA$, where $A$ is an invertible square matrix, or symmetric matrices with all *strictly positive* eigenvalues. A familiar positive definite matrix is the identity matrix, $I_n$.\n",
    "\n",
    "Then, $M$ induces an [inner product](#inner_defn) given by $\\langle \\vv u, \\vv v \\rangle_M = \\vv u^T M \\vv v$. In the case that $M$ is diagonal, this is the [weighted dot product](#weighted-dot-product-ex) we have seen before. Try for yourselves to verify that $\\langle \\vv u, \\vv v \\rangle_M$ indeed satisfies all axioms of an inner product.\n",
    "\n",
    "The inner product in turn induces a norm $\\|\\vv v\\|_M = \\sqrt{\\langle \\vv v, \\vv v\\rangle}_M = \\sqrt{\\vv v^T M \\vv v}$.\n",
    "\n",
    "TODO: Probably want to move this to the norms lesson\n",
    "\n",
    "\n",
    "\n",
    ":::\n",
    "\n",
    ":::{prf:example} Distances on a connected graph\n",
    ":label:distance-connected_graph_ex\n",
    "\n",
    "In this example, we'll demonstrate how the [definition of a distance function](#general_distance_defn) can be satisfied when the underlying space isn't a vector space. We will consider the *shortest walk distance on a connected undirected graph*.\n",
    "\n",
    "An undirected graph consists of a set of *vertices* and *edges* which connect 2 vertices. Often times, undirected graphs are drawn as follows: the vertices are dots, and edges are lines connecting 2 dots. So we can represent an example of an undirected graph with the image below. (For our purposes, we will assume that each pair of vertices can have at most 1 edge connecting them, and that no vertex has an edge to itself.)\n",
    "\n",
    "\n",
    "\n",
    "![alt text](../figures/04-graph_distance.png)\n",
    "\n",
    "A *walk* in an undirected graph is a sequence of vertices $v_1, v_2, ..., v_{k - 1}, v_k$ such that there is an edge between adjacent vertices in this sequence. The number of edges in the walk is its *length*. In the image, for example, $3 \\to 5\\to 6\\to 10$ is a walk with length 3.\n",
    "\n",
    "We say an undirected graph is *connected* if there is at least one walk between every pair of vertices. The above graph is connected.\n",
    "\n",
    "If a graph is connected, then we can define the *shortest walk distance* as follows. For vertices $u, v$ in our graph, their shortest walk distance is defined as \n",
    "\n",
    "\\begin{align*}\n",
    "    \\text{dist}(u, v) = \\text{length of shortest walk starting at $u$ and ending at $v$}\n",
    "\\end{align*}\n",
    "\n",
    "We will verify that the shortest walk distance indeed satisfies the three axioms of a distance function.\n",
    "\n",
    "1. **Symmetry.** For any two vertices $u, v$, let $P = u \\to ... \\to v$ be a minimum length walk (with length $l$) starting at $u$ and ending at $v$. If we reverse $P$, we get a walk starting at $v$ and ending at $u$ with length $l$. This means that $d(v, u) \\leq l = d(u, v)$.\n",
    "\n",
    "    Next, let $Q = v\\to ...\\to u$ be a minimum length walk starting at $v$ and ending at $u$ (with length $l'$). If we reverse $Q$, we get a walk starting at $u$ and ending at $v$ with length $l'$. This means that $d(u, v) \\leq l' = d(v, u)$.\n",
    "\n",
    "    Taken together, these two inequalities imply that $d(u, v) = d(v, u)$, i.e., the shortest walk distance is symmetric.\n",
    "\n",
    "2. **Positivity.** For vertices $u \\neq v$, it will take at least one edge to go from $u$ to $v$, implying that $d(u, v) > 0$ if $u \\neq v$. Also, $d(v, v) = 0$ because we can take the trivial walk $P = v$, which has no edges. \n",
    "\n",
    "3. **Triangular Inequality.** For vertices $u, v, w$, we want to show that \n",
    "\n",
    "    \\begin{align*}\n",
    "    d(u, w) \\leq d(u, v) + d(v, w)\n",
    "    \\end{align*}\n",
    "\n",
    "    Note that if $P_{uv}$ is a walk of length $d(u, v)$ from $u$ to $v$, and $P_{vw}$ is a walk of length $d(v, w)$ from $v$ to $w$, then we can concatenate $P_{uv} \\to P_{vw}$ to get a walk starting from $u$ which ends at $w$ and has length $d(u, v) + d(v, w)$. Since the shortest walk from $u$ to $w$ can't be longer than this walk we just constructed, this implies that $d(u, w) \\leq d(u, v) + d(v, w)$, i.e., the triangular inequality holds.\n",
    "\n",
    "\n",
    ":::\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Applications of Distances\n",
    "\n",
    ":::{prf:example} Feature distances\n",
    ":label:distance-feature_distance\n",
    "\n",
    "If $\\vv x, \\vv y \\in V$ are vectors containing *features* of two objects, $\\|\\vv  x - \\vv  y\\|$ is called the *feature distance*. It gives a measure of how \"different\" two objects are. \n",
    "\n",
    "For example, suppose each vector represents a patient in a hospital with entries such as age, weight, height, and test results. We can use $\\| \\vv x - \\vv y\\|$ to check if patients $\\vv x$ and $\\vv y$ are \"close\" to each other with respect to these features.\n",
    ":::\n",
    "\n",
    ":::{prf:example} Nearest neighbors\n",
    ":label:distance-nearest_neighbors\n",
    "\n",
    "Suppose we are given a collection $\\vv {z_1}, ..., \\vv {z_m} \\in V$ of $m$ vectors living in a vector space $V$. We say that $\\vv{z_j}$ is the *nearest neighbor* of $\\vv {x}$ among the vectors $\\vv {z_1}, ..., \\vv {z_m} \\in V$ if \n",
    "\n",
    "\\begin{align*}\n",
    "    \\| \\vv x - \\vv{z_j} \\| \\leq \\| \\vv x - \\vv{z_i} \\| \\quad\\text{for i = 1, ..., m}\n",
    "\\end{align*}\n",
    "\n",
    "In words, this means $\\vv{z_j}$ is the closest vector to $\\vv x$ among $\\vv{z_1}, ..., \\vv{z_m}$. This is illustrated below; we note that the nearest neighbor may not be unique (e.g., if several $\\vv{z_i}$ satisfy the condition above).\n",
    "\n",
    ":::{figure}../figures/04-nearest_neighbor.png\n",
    ":label:Nearest neighbor\n",
    ":alt: Nearest neighbor to a vector $\\vv x \\in \\mathbb{R}^2$\n",
    ":width: 400px\n",
    ":align: center\n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
