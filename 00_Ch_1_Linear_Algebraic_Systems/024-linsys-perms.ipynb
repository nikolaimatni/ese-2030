{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd7554ca-5ac4-4958-b713-648e3fd54114",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "---\n",
    "title: 1.6 The Permuted LU-Factorization\n",
    "subject:  Linear Algebraic Systems\n",
    "subtitle: Let's mix things up a little\n",
    "short_title: 1.6 Permuted LU-Factorization\n",
    "authors:\n",
    "  - name: Nikolai Matni\n",
    "    affiliations:\n",
    "      - Dept. of Electrical and Systems Engineering\n",
    "      - University of Pennsylvania\n",
    "    email: nmatni@seas.upenn.edu\n",
    "license: CC-BY-4.0\n",
    "keywords: systems of linear equations, permutation matrices, interchanging rows\n",
    "math:\n",
    "  '\\vv': '\\mathbf{#1}'\n",
    "  '\\bm': '\\begin{bmatrix}'\n",
    "  '\\em': '\\end{bmatrix}'\n",
    "  '\\R': '\\mathbb{R}'\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc99dddf-5c7e-4c92-8111-fb156f6af7fe",
   "metadata": {},
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/nikolaimatni/ese-2030/HEAD?labpath=/00_Ch_1_Linear_Algebraic_Systems/024-linsys-perms.ipynb)\n",
    "\n",
    "{doc}`Lecture notes <../lecture_notes/Lecture 02 - Pivots + Permutations, Matrix Inverses (Gauss-Jordan), Transposes, Symmetric Matrices, and General Linear Systems.pdf>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efca8556-3e7f-4f1c-b466-04f0e14b12e5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Reading\n",
    "Material related to this page, as well as additional exercises, can be found in ALA Ch. 1.4, LAA Ch 2.5, and ILA Ch. 2.4.  These notes are mostly based on ALA Ch 1.4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170438e7",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "By the end of this page, you should know:\n",
    "- how to solve linear equations if $A$ is not regular\n",
    "- what are permutation matrices\n",
    "- how to use permuted LU factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05083d8-ef6c-469a-9cf5-388ed048fa0b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Interchanging Rows\n",
    "\n",
    "The method of Gaussian Elimination works only if the matrices are regular. However, not every matrix is regular as given in the example below.\n",
    "\n",
    "<!-- [^regular]: We'll call a square matrix $A$ _regular_ if Gaussian Elimination successfully reduces $A$ to the upper triangular form $U$ with all nonzero pivots on the diagonal.  If this fails to happen, i.e., if a pivot appearing on the diagonal is zero, then the matrix is not regular. -->\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\label{non_regular}\n",
    "2y + z & = 2,\\\\\n",
    "2x +6y + z & = 7,\\\\\n",
    "x+y+4z & =3,\n",
    "\\end{eqnarray}\n",
    "\n",
    "The augmented coefficient matrix for the above set of equations is\n",
    "\n",
    "\\begin{equation}\n",
    "\\label{augm}\n",
    "\\left[ \\begin{array}{ccc|c} 0 & 2 & 1 & 2\\\\ 2& 6 & 1 & 7\\\\ 1 & 1 & 4 & 3 \\end{array}\\right].\n",
    "\\end{equation}\n",
    "\n",
    "In the above example, the entry $(1,1)$ is 0, which is the first diagonal element, but cannot serve as a pivot. The \"problem\" is because $x$ does not appear in the first equation, but this is actually a good thing because we already have an equation that has only two variables in it. Hence, we need to eliminate $x$ from only one of the other two equations. Let us interchange the first two rows of [](#augm):\n",
    "\n",
    "\\begin{equation}\n",
    "\\label{augm_swap}\n",
    "\\left[ \\begin{array}{ccc|c}  2& 6 & 1 & 7\\\\ 0 & 2 & 1 & 2\\\\ 1 & 1 & 4 & 3 \\end{array}\\right],\n",
    "\\end{equation}\n",
    "\n",
    "which clearly does not change the solution set, but now we have a pivot at $(1,1)$ and $(2,2)$. Interchanging the first and second row is equivalent to swapping the first and second equation. Now, we can proceed as in Gaussian Elimination to zero out $(3, 1)$ and $(3, 2)$ using [elementary row operations](./023-linsys-gauuss.ipynb#rowop1) to get  \n",
    "\n",
    "\\begin{equation}\n",
    "\\label{augm_swap}\n",
    "\\left[ \\begin{array}{c|c}  U &  \\textbf{c} \\end{array}\\right] = \n",
    "\\left[ \\begin{array}{ccc|c}  2& 6 & 1 & 7\\\\ 0 & 2 & 1 & 2\\\\ 0 & 0 & \\frac{9}{2} & \\frac{3}{2} \\end{array}\\right].\n",
    "\\end{equation}\n",
    "\n",
    "The pivots are $2, 2, \\frac{9}{2}$ and solving via back substitution yields the solution $x=\\frac{5}{6}, y = \\frac{5}{6}, z = \\frac{1}{3}$. \n",
    "\n",
    "This row swapping operation is pretty useful, and so we'll make it another elementary row operation, in addition to the [type 1 operation](./023-linsys-gauss.ipynb#rowop1) of adding rows of a matrix together that we've been relying on so far.\n",
    "\n",
    "(rowop2)=\n",
    "```{prf:observation} Elementary Row Operation \\#2\n",
    ":label: rowop2\n",
    "Interchanging two rows of the augmented matrix $M$ is the equivalent of swapping two equations in the system of linear equations it defines. As such, this does not change the solution set and leads to an equivalent augmented matrix.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0046940-e205-406f-a3d1-94a0bb0cddcb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Square matrices $A$ that can be reduced to upper triangular form with nonzeros along the diagonal via Gaussian Elimination with pivoting play a distingished role in linear algebra.  As we'll see shortly, when such matrices are used to define a system of linear equations $A\\vv x = \\vv b$, we know that there will be a unique solution for _any choice_ of right hand side $\\vv b$.  Because these kinds of matrices are so important, we'll give them a name and call them _nonsingular_.  Why we call them this will become clearer later in the course, but for now, this will just be our name for \"nice\" matrices $A$ as described below.\n",
    "\n",
    "```{prf:definition} Nonsingular\n",
    ":label: nonsingular\n",
    "A square matrix is called _nonsingular_ if it can be reduced to upper triangular form with all non-zero elements on the diagonal — the pivots — by elementary row operations of types [1](./023-linsys-gauss.ipynb#rowop1) and [2](#rowop2).\n",
    "```\n",
    "\n",
    "In contrast, a singular square matrix cannot be reduced to such upper triangular form\n",
    "by such row operations, because at some stage in the elimination procedure the diagonal\n",
    "pivot entry and all of the entries below it are zero. \n",
    "\n",
    "```{warning}\n",
    ":label: nonsingular_regular\n",
    "Every regular matrix is nonsingular, but, as we just saw, not every nonsingular matrix is regular.\n",
    "```\n",
    "\n",
    "We summarize the discussion about unique solutions of systems of equations for nonsingular $A$ in the theorem below.\n",
    "```{prf:theorem} Uniqueness of solution\n",
    ":label: uniqueness\n",
    "A linear system $A \\textbf{x} = \\textbf{b}$ has a unique solution for every choice of right-hand side $b$ if and only if its coeﬃcient matrix $A$ is square and [nonsingular](#nonsingular).\n",
    "```\n",
    "We are able to prove the “if” part of this theorem, since we know that when $A$ is nonsingular, we know that Gaussian Elimination with pivoting succeeds, meaning that the solution exists and is unique. We'll come back to prove the “only if” part later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfebd67e-0243-4689-b5a6-bc60b3414c21",
   "metadata": {},
   "source": [
    "## Small Pivots Cause Numerical Issues\n",
    "\n",
    "It's important to remember then when linear algebra is applied in engineering, data science, economics, and scientific domains, it is done so using computers.  Computers store data using bits (0s and 1s), and as such have _limited precision_.  This means that computers have to eventually round off numbers, because they can't keep an infinite number of decimal points.  This matters because when the numbers you are working with span a very large range (i.e., some numbers are _very big_ and others are _very small_), then even very small rounding errors introduced by the limits of your computer can cause significant errors in your solutions.  Here we'll look at a simple example of such _numerical ill-conditionning_, and see that by being cognizant of these issues, we can find a work around.\n",
    "\n",
    "We'll look at the simple system of two equations in two unknowns:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\label{small_pivot}\n",
    "0.01x +1.6y & = 32.1,\\\\\n",
    "x+0.6y & = 22,\n",
    "\\end{eqnarray}\n",
    "\n",
    "where, the exact solution is $x=10, y=20$ (you can check this). Now let's assume that we have only have a very primitive computer for solving this system of equations that only retains three digits for any number we store in it.  Of course, modern computers have much higher, but still finite, capacity.  We can modify the exmaple below to produce similar issues on modern computers. \n",
    "\n",
    "The actual augmented matrix is given below after making it upper triangular.\n",
    "\n",
    "\\begin{equation} \n",
    "\\left[ \\begin{array}{cc|c}  .01 & 1.6 & 32.1\\\\ 1 & .6 & 22 \\end{array}\\right] \\leftrightarrow \n",
    "\\left[ \\begin{array}{cc|c}  .01 & 1.6 & 32.1\\\\ 0 & -159.4 & -3188 \\end{array}\\right].\n",
    "\\end{equation}\n",
    "\n",
    "Since the calculator only retains three digits, the matrix computed by our primitive computer is instead\n",
    "\\begin{equation} \n",
    "\\label{small_pivot_augm} \n",
    "\\left[ \\begin{array}{cc|c}  .01 & 1.6 & 32.1\\\\ 0 & -159 & -319 \\end{array}\\right].\n",
    "\\end{equation}\n",
    "\n",
    "If we use back substitution with the rounded augmented matrix [](#small_pivot_augm) to solve the system by, we get first get $y = \\frac{-3190}{159} \\approx 20.1$.  Well that's not too bad, we're only off by 0.1 in $y$.  But, if we proceed to solve for $x$ using this value of $y$, we get  $x \\approx -10$! This is a big problem! A small error in $y$, i.e,  0.1, produced a huge error in $x$! The problem is because of the small pivot $0.01$ at $(1,1)$. The small error in $y$ is scaled up when evaluating the first equation, where we have to divide the exression by the small pivot $0.01$. If we interchanged the rows so that the pivot is $1$ and proceed from there via Gaussian Elimination, the approximate solution is ${y \\approx 20.1, x \\approx 9.9}$, which is much more reasonable.\n",
    "\n",
    "```{tip}\n",
    ":label: interchange_small_pivot\n",
    "Small pivots cause issues in numerical computations. Use row interchanges to avoid small pivots.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d47473f-4b98-412f-9fa8-8dfc38dc8296",
   "metadata": {},
   "source": [
    "## Permutation matrices\n",
    "\n",
    "Similar to how [type 1 operations](./023-linsys-gauss.ipynb#rowop1) are represented using [elementary matrices](./023a-linsys-LU.ipynb#elementary), we can represent [type 2 operations](rowop2) using _permutation matrices_. \n",
    "\n",
    "```{prf:definition} Permutation matrices\n",
    ":label: perm_matrix\n",
    "A permutation matrix is a matrix obtained from the identity matrix by _any_ combination of row interchanges.\n",
    "```\n",
    "\n",
    "For example, to swap rows 1 and 2 of the matrix $A$, we left multiply $A$ by $P$ as follows.\n",
    "\n",
    "\\begin{equation} \n",
    "\\label{perm_matrix} \n",
    "A = \\begin{bmatrix}\n",
    "1 & 2 & 3 \\\\\n",
    "4 & 5 & 6 \\\\\n",
    "7 & 8 & 9\n",
    "\\end{bmatrix}, P = \\begin{bmatrix}\n",
    "0 & 1 & 0 \\\\\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix} \\Rightarrow PA = \\begin{bmatrix}\n",
    "4 & 5 & 6 \\\\\n",
    "1 & 2 & 3 \\\\\n",
    "7 & 8 & 9\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "```{note} Also a Permutation matrix\n",
    ":label: perm_matrix_alt\n",
    "A matrix $P$ is a permutation matrix if and only if each row of $P$ contains all $0$ entries except for a single $1$, and, in addition, each column of $P$ also contains all $0$ entries except for a single $1$\n",
    "```\n",
    "\n",
    ":::{important} Properties\n",
    "1. If $P_1, P_2$ are permutation matrices, then their products $P_1P_2, P_2P_1$ are also permutation matrices.\n",
    "2. In general, permutation matrices do not commute $P_1P_2 \\neq P_2P_1$, since the order of swapping matters.\n",
    "3. If $P_1$ is a permutation matrix that swaps exactly one row with another, then $P_1P_1 = I$, because the inverse operation of interchanging two rows is the same original operation. This is **not true** for general permutation matrices that encode multiple swaps. \n",
    ":::\n",
    "\n",
    "#### Python Break!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc85b0d4-9ec3-401c-a133-2cb703c2410c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 5, 6],\n",
       "       [1, 2, 3],\n",
       "       [7, 8, 9]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "P = np.array([[0, 1, 0], [1, 0, 0], [0, 0, 1]])\n",
    "A = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "#Swap rows 1 and 2 of A\n",
    "P @ A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75c14f8-45ce-4627-89a8-b27503907c78",
   "metadata": {},
   "source": [
    "## Permuted LU-factorization\n",
    "\n",
    "From [](#nonsingular), every nonsingular matrix $A$ can be reduced to upper triangular form using [type 1 operations](./023-linsys-gauss.ipynb#rowop1) and [type 2 operations](#rowop2). If we perform all the permutations first using a permutation matrix $P$, then we obtain a [regular matrix](./023a-linsys-LU.ipynb#regular_matrix) $PA$ that admits an $LU$ factorization. Hence we can define the _permuted LU factorization_ of a nonsingular matrix $A$ as follows.\n",
    "\n",
    ":::{prf:definition} Permuted LU factorization\n",
    ":label: plu-factorization-defn\n",
    "\n",
    "Any square matrix $A$ can be written in the form:\n",
    "\n",
    "\\begin{equation} \n",
    "\\label{perm_LU} \n",
    "PA = LU\n",
    "\\end{equation}\n",
    "\n",
    "This is known as a permuted-LU-factorization, or PLU-factorization, of $A$.\n",
    ":::\n",
    "\n",
    "Given a permuted LU factorization of the matrix $A$, we can solve the system of equations by first doing forward substitution with $L\\textbf{z}= P\\textbf{b}$ and back substitution with $U\\textbf{x} = \\textbf{z}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd4eb89",
   "metadata": {},
   "source": [
    "````{exercise} Permuting a linear system\n",
    ":label: linsys-perms-ex1\n",
    "\n",
    "Consider the following linear system:\n",
    "\n",
    "\\begin{align*}\n",
    "    x + 2y + z = -2\\\\\n",
    "    2x + 4y - z = 12\\\\\n",
    "    -x + y - z = 5\n",
    "\\end{align*}\n",
    "\n",
    "Show that the coefficient matrix\n",
    "\n",
    "\\begin{align*}\n",
    "    A = \\bm \n",
    "        1 & 2 & 1 \\\\\n",
    "        2 & 4 & -1 \\\\\n",
    "        -1 & 1 & -1\n",
    "    \\em\n",
    "\\end{align*}\n",
    "\n",
    "is irregular. \n",
    "\n",
    "Then, given the permutation matrix\n",
    "\n",
    "\\begin{align*}\n",
    "    P = \\bm\n",
    "        1&0&0\\\\\n",
    "        0&0&1\\\\\n",
    "        0&1&0\n",
    "    \\em\n",
    "\\end{align*}\n",
    "\n",
    "show that the permuted coefficient matrix $PA$ is regular. \n",
    "\n",
    "Finally, solve the permuted system $PA = P \\mathbf b$ by first computing the $LU$ factorization of $PA$, and then using forward and back substitution with $PA\\mathbf x = LU\\mathbf x = P\\mathbf b$.\n",
    "\n",
    ":::{hint} Click me for a hint!\n",
    ":class: dropdown\n",
    "Remember, a matrix is regular if and only if it has an $LU$ factorization. What happens when we run the $LU$ factorization algorithm on $A$?\n",
    "\n",
    ":::\n",
    "```{solution} linsys-perms-ex1\n",
    ":class: dropdown\n",
    "\n",
    "First, let's prove that $A$ is irregular. Let's run the $LU$ factorization algorithm on $A$ (which is really just Gaussian elimination). With $1$ as our first pivot, we eliminate column 1:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\underbrace{\\bm 1&2&1\\\\2&4&-1\\\\-1&1&-1 \\em}_A &= \\bm 1&0&0\\\\0&1&0\\\\0&0&1\\em \\bm 1&2&1\\\\2&4&-1\\\\-1&1&-1 \\em\\\\\n",
    "    &= \\bm 1&0&0\\\\0&1&0\\\\0&0&1\\em\\left(\\bm 1&0&0\\\\2&1&0\\\\-1&0&1 \\em \\bm 1&0&0\\\\-2&1&0\\\\1&0&1 \\em\\right) \\bm 1&2&1\\\\2&4&-1\\\\-1&1&-1 \\em\\\\\n",
    "    &=\\left(\\bm 1&0&0\\\\0&1&0\\\\0&0&1\\em\\bm 1&0&0\\\\2&1&0\\\\-1&0&1 \\em \\right)  \\left(\\bm 1&0&0\\\\-2&1&0\\\\1&0&1 \\em \\bm 1&2&1\\\\2&4&-1\\\\-1&1&-1 \\em\\right)\\\\\n",
    "    &=\\bm 1&0&0\\\\2&1&0\\\\-1&0&1 \\em \\bm 1&2&1\\\\0&0&-3\\\\0&3&0 \\em\n",
    "\\end{align*}\n",
    "\n",
    "Uh oh! Our second pivot (the element at position (2, 2) of the rightmost matrix in the bottom expression) is now zero, so the $LU$ factorization algorithm fails. This means that $A$ doesn't have an $LU$ factorization, so $A$ is irregular.\n",
    "\n",
    "The permuted matrix $PA$ is\n",
    "\n",
    "\\begin{align*}\n",
    "    PA = \\underbrace{\\bm\n",
    "        1&0&0\\\\\n",
    "        0&0&1\\\\\n",
    "        0&1&0\n",
    "    \\em}_P \\underbrace{\\bm 1&2&1\\\\2&4&-1\\\\-1&1&-1 \\em}_A = \\bm 1&2&1\\\\-1&1&-1\\\\2&4&-1 \\em\n",
    "\\end{align*}\n",
    "\n",
    "Now, let's run the $LU$ factorization algorithm on $PA$. With $1$ as our first pivot, we eliminate column $1$:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\underbrace{\\bm 1&2&1\\\\-1&1&-1\\\\2&4&-1 \\em}_{PA} &= \\bm 1&0&0\\\\0&1&0\\\\0&0&1\\em \\bm 1&2&1\\\\-1&1&-1\\\\2&4&-1 \\em\\\\\n",
    "    &= \\bm 1&0&0\\\\0&1&0\\\\0&0&1\\em\\left(\\bm 1&0&0\\\\-1&1&0\\\\2&0&1 \\em \\bm 1&0&0\\\\1&1&0\\\\-2&0&1 \\em\\right) \\bm 1&2&1\\\\-1&1&-1\\\\2&4&-1 \\em\\\\\n",
    "    &= \\left(\\bm 1&0&0\\\\0&1&0\\\\0&0&1\\em\\bm  1&0&0\\\\-1&1&0\\\\2&0&1 \\em\\right) \\left(\\bm 1&0&0\\\\1&1&0\\\\-2&0&1 \\em\\bm 1&2&1\\\\-1&1&-1\\\\2&4&-1 \\em\\right)\\\\\n",
    "    &= \\underbrace{\\bm 1&0&0\\\\-1&1&0\\\\2&0&1 \\em}_L \\underbrace{\\bm 1&2&1\\\\0&3&0\\\\0&0&-3 \\em}_U\n",
    "\\end{align*}\n",
    "\n",
    "For this exercise, we had a small 3x3 system, so that's it for the $LU$ factorization algorithm! \n",
    "\n",
    "The last step is to solve with forwardsubstition and backsubstitution on the system:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\underbrace{\\bm 1&0&0\\\\-1&1&0\\\\2&0&1 \\em}_L \\underbrace{\\bm 1&2&1\\\\0&3&0\\\\0&0&-3 \\em}_U \\underbrace{\\bm x\\\\y\\\\z \\em}_{\\mathbf x} = \\underbrace{\\bm -2\\\\5\\\\12 \\em}_{P \\mathbf b}\n",
    "\\end{align*}\n",
    "\n",
    "And we get:\n",
    "\n",
    "\\begin{align*}\n",
    "    U\\mathbf x = \\bm -2\\\\3\\\\18 \\em, \\quad \\mathbf x = \\bm 2\\\\ 1\\\\ -6\\em\n",
    "\\end{align*}\n",
    "\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01559894",
   "metadata": {},
   "source": [
    "```{prf:example} Simultaneously finding the P, L, and U matrices\n",
    "\n",
    "So far, we've learned that *every* nonsingular square matrix $A$ has at least one factorization of the form $PA = LU$, where $P$ is a permutation matrix and $L, U$ are lower and upper triangular, respectively. \n",
    "\n",
    "In [](#linsys-perms-ex1), you were given the permutation $P$ beforehand. But what if don't have prior knowledge of $P$?\n",
    "\n",
    "It turns out that, given a square nonsingular matrix $A$, we can compute the $P, L, U$ matrices simultaneously. In this example, we'll demonstrate a procedure for computing $P, L, U$ simultaneously using the same system as [](#linsys-perms-ex1). It's basically just Gaussian elimination with row swaps!\n",
    "\n",
    "First, let's write out the obvious equality \n",
    "\n",
    "\\begin{align*}\n",
    "    \\underbrace{\\bm 1&0&0\\\\0&1&0\\\\0&0&1 \\em}_{\"P\"}\\underbrace{\\bm 1&2&1\\\\2&4&-1\\\\-1&1&-1 \\em}_A = \\underbrace{\\bm 1&0&0\\\\0&1&0\\\\0&0&1 \\em}_{\"L\"} \\underbrace{\\bm 1&2&1\\\\2&4&-1\\\\-1&1&-1 \\em}_{\"U\"}\n",
    "\\end{align*}\n",
    "\n",
    "You'll note that the RHS has 2 matrices named $\"L\"$ and $\"U\"$. The idea of the procedure is to use some matrix algebra rules to transform $\"L\"$ into a lower tringular matrix and $\"U\"$ into an upper triangular matrix. In the process, we are going to build up the permutation matrix $\"P\"$.\n",
    "\n",
    "Starting off, let's use $1$ as our first pivot to eliminate column 1:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\underbrace{\\bm 1&0&0\\\\0&1&0\\\\0&0&1 \\em}_{\"P\"}\\underbrace{\\bm 1&2&1\\\\2&4&-1\\\\-1&1&-1 \\em}_A &= \\underbrace{\\bm 1&0&0\\\\0&1&0\\\\0&0&1\\em}_{\"L\"} \\underbrace{\\bm 1&2&1\\\\2&4&-1\\\\-1&1&-1 \\em}_{\"U\"}\\\\\n",
    "    &= \\bm 1&0&0\\\\0&1&0\\\\0&0&1\\em\\left(\\bm 1&0&0\\\\2&1&0\\\\-1&0&1 \\em \\bm 1&0&0\\\\-2&1&0\\\\1&0&1 \\em\\right) \\bm 1&2&1\\\\2&4&-1\\\\-1&1&-1 \\em\\\\\n",
    "    &=\\left(\\bm 1&0&0\\\\0&1&0\\\\0&0&1\\em\\bm 1&0&0\\\\2&1&0\\\\-1&0&1 \\em \\right)  \\left(\\bm 1&0&0\\\\-2&1&0\\\\1&0&1 \\em \\bm 1&2&1\\\\2&4&-1\\\\-1&1&-1 \\em\\right)\\\\\n",
    "    &=\\underbrace{\\bm 1&0&0\\\\2&1&0\\\\-1&0&1 \\em}_{\"L\"} \\underbrace{\\bm 1&2&1\\\\0&0&-3\\\\0&3&0 \\em}_{\"U\"}\n",
    "\\end{align*}\n",
    "\n",
    "Just like in [](#linsys-perms-ex1), we run into the same issue of a zero pivot. How can we fix this? Recall that for any permutation matrix $P$ swapping 2 rows, $PP = I$ (In this case, we want $P$ to be the permutation matrix swapping rows 2 and 3 of $\"U\"$). We can cleverly insert this expression in the middle of $\"L\"$ and $\"U\"$, and use associativity of matrix multiplication to get:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\underbrace{\\bm 1&0&0\\\\0&1&0\\\\0&0&1 \\em}_{\"P\"}\\underbrace{\\bm 1&2&1\\\\2&4&-1\\\\-1&1&-1 \\em}_A &=\\underbrace{\\bm 1&0&0\\\\2&1&0\\\\-1&0&1 \\em}_{\"L\"} \\underbrace{\\bm 1&2&1\\\\0&0&-3\\\\0&3&0 \\em}_{\"U\"}\\\\\n",
    "    &= \\underbrace{\\bm 1&0&0\\\\2&1&0\\\\-1&0&1 \\em}_{\"L\"} \\left( \\bm 1&0&0\\\\0&0&1\\\\0&1&0 \\em \\bm 1&0&0\\\\0&0&1\\\\0&1&0 \\em \\right) \\underbrace{\\bm 1&2&1\\\\0&0&-3\\\\0&3&0 \\em}_{\"U\"}\\\\\n",
    "    &= \\left(\\underbrace{\\bm 1&0&0\\\\2&1&0\\\\-1&0&1 \\em}_{\"L\"} \\bm 1&0&0\\\\0&0&1\\\\0&1&0 \\em  \\right)\\left(\\bm 1&0&0\\\\0&0&1\\\\0&1&0 \\em  \\underbrace{\\bm 1&2&1\\\\0&0&-3\\\\0&3&0 \\em}_{\"U\"}\\right)\\\\\n",
    "    &= \\underbrace{\\bm 1&0&0\\\\2&0&1\\\\-1&1&0 \\em}_{\"L\"} \\underbrace{\\bm 1&2&1\\\\0&3&0\\\\0&0&-3 \\em}_{\"U\"}\n",
    "\\end{align*}\n",
    "\n",
    "We're almost there! However, our \"L\" matrix isn't lower triangular yet! Not to worry, we can fix this with a single row swap: \n",
    "\\begin{align*}\n",
    "    &\\underbrace{\\bm 1&0&0\\\\0&1&0\\\\0&0&1 \\em}_{\"P\"}\\underbrace{\\bm 1&2&1\\\\2&4&-1\\\\-1&1&-1 \\em}_A =\\underbrace{\\bm 1&0&0\\\\2&0&1\\\\-1&1&0 \\em}_{\"L\"} \\underbrace{\\bm 1&2&1\\\\0&3&0\\\\0&0&-3 \\em}_{\"U\"}\\\\\n",
    "    &\\underset{\\text{(implies)}}{\\implies} \\bm 1&0&0\\\\0&0&1\\\\0&1&0 \\em \\underbrace{\\bm 1&0&0\\\\0&1&0\\\\0&0&1 \\em}_{\"P\"}\\underbrace{\\bm 1&2&1\\\\2&4&-1\\\\-1&1&-1 \\em}_A = \\bm 1&0&0\\\\0&0&1\\\\0&1&0 \\em\\underbrace{\\bm 1&0&0\\\\2&0&1\\\\-1&1&0 \\em}_{\"L\"} \\underbrace{\\bm 1&2&1\\\\0&3&0\\\\0&0&-3 \\em}_{\"U\"}\\\\\n",
    "    &\\implies \\underbrace{\\bm 1&0&0\\\\0&0&1\\\\0&1&0 \\em}_{\"P\"}\\underbrace{\\bm 1&2&1\\\\2&4&-1\\\\-1&1&-1 \\em}_A = \\underbrace{\\bm 1&0&0\\\\-1&1&0\\\\2&0&1 \\em}_{\"L\"} \\underbrace{\\bm 1&2&1\\\\0&3&0\\\\0&0&-3 \\em}_{\"U\"}\n",
    "\\end{align*}\n",
    "\n",
    "(An astute reader might notice that $\"L\"$ was unchanged from multiplying it from both the left and right by $P$ (i.e., $\"L\" = P \\times \"L\" \\times \"P\"$) where $P$ was the row swap we defined above. This is no coincidence, and stems from the fact that $\"L\"$ has a particular structure which we will discuss later.)\n",
    "\n",
    "And we're done! But this example was only for a small 3x3 system, where we only had to make one row swap. Let's try to distill the essence of what we just did into a more general procedure to compute the $PA = LU$ factorization of any square nonsingular matrix (this same procedure will generalize to nonsquare matrices as well).\n",
    "\n",
    "* First, initialize your matrices:\n",
    "\n",
    "  * $\"P\"$ starts off as the identity matrix.\n",
    "\n",
    "  * $\"L\"$ starts off as the identity matrix.\n",
    "\n",
    "  * $\"U\"$ starts off as the input coefficient matrix $A$.\n",
    "\n",
    "* Second, we are going to perform a series of steps (Step $1$, Step $2$, ..., Step $n$) such that at end of Step $k$, for $k = 1, 2, ..., n$, the following *invariants* are satisfied:\n",
    "\n",
    "  * $\"P\"\\times A = \"L\" \\times \"U\"$.\n",
    "\n",
    "  * $\"P\"$ is a permutation matrix.\n",
    " \n",
    "  * $L$ is lower triangular.\n",
    "\n",
    "  * The *trailing* (bottomright-most) $(n - k) \\times (n - k)$ submatrix of $\"L\"$ is the identity matrix and only has zeros above it in $L$.\n",
    "\n",
    "  * The *leading* (topleft-most) $k \\times k$ submatrix of $U$ is upper triangular and only has zeros below it in $\"U\"$.\n",
    "\n",
    "  If we do the following, we can always preserve these invariants. At Step $k$,\n",
    "\n",
    "  * If the pivot at position $(k, k)$ is nonzero, then continue onto the next step. Otherwise, swap it with an element *below it*, and *left multiply* $\"P\"$ by the permutation matrix corresponding to the rows that were swapped.\n",
    "  \n",
    "  * Use said pivot at position $(k, k)$ to eliminate the entries *below it* by *left multiplying* $\"U\"$ by some elementary matrices, and *right multiplying* \"L\" by the inverse of those elementary matrices.\n",
    "\n",
    "* Finally, by our invariants, at the end of Step $n$: $\"P\"$, $\"L\"$, $\"U\"$ will be the $PA = LU$ factorization of $A$.\n",
    "\n",
    "In this course, we don't place an emphasis on the gritty details behind this procedure, so we won't prove it's correctness here. But still, try to convince yourself that this procedure works for square, nonsingular matrices!\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62329db-27f2-400a-82e3-e7bb34f6a2f2",
   "metadata": {},
   "source": [
    "#### Python Break!\n",
    "Implementing the algorithms you learn in this class from scratch in NumPy is a great way to both gain a deeper understanding of the math and to practice your coding skills.  However, when applying these ideas in real word situations, it is usually better to use built-in functions: these typically have 100s, if not 1000s, of engineering hours behind them, and have been optimized for reliability, performance, and scalability.  In the code snippet below, we use the standard scientific computing package [SciPy](https://scipy.org/)'s built in `lu` implementation for the [LU-factorization (with pivots)](https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.lu.html).  Note that this implementation is slightly different than the one described in our notes, and instead computes $P, L, U$ such that $A = PLU$.  By the end of the next section on matrix inverses, you'll know how to relate this expression to the one we described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "567468ed-5e61-4134-8e8d-33617206a7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: \n",
      " [[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]] \n",
      "L: \n",
      " [[ 1.   0.   0. ]\n",
      " [ 0.   1.   0. ]\n",
      " [ 0.5 -1.   1. ]] \n",
      "U: \n",
      " [[2.  6.  1. ]\n",
      " [0.  2.  1. ]\n",
      " [0.  0.  4.5]]\n",
      "A - P L U =\n",
      " [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Permuted LU factorization\n",
    "\n",
    "import numpy as np\n",
    "from scipy.linalg import lu\n",
    "\n",
    "A = np.array([[0, 2, 1],\n",
    "              [2, 6, 1],\n",
    "              [1, 1, 4]])\n",
    "P, L, U = lu(A)\n",
    "print(\"P: \\n\", P, \"\\nL: \\n\", L, \"\\nU: \\n\", U)\n",
    "print(f'A - P L U =\\n {A - P @ L @ U}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6222fe8f-50e4-437b-8831-a45119487043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$max|(A - P L U)_ij| =\n",
      " 1.461053500406706e-13\n"
     ]
    }
   ],
   "source": [
    "# Let's try a bigger example!  How big can you make n before it takes too long to solve?\n",
    "\n",
    "n = 2000\n",
    "A = np.random.randn(n,n)\n",
    "\n",
    "P, L, U = lu(A)\n",
    "print(f'$max|(A - P L U)_ij| =\\n {np.max(np.abs(A - P @ L @ U))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39165c0f-fa19-44ce-8eac-09ed6d261942",
   "metadata": {},
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/nikolaimatni/ese-2030/HEAD?labpath=/00_Ch_1_Linear_Algebraic_Systems/024-linsys-perms.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
