{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Orthogonal Matrices\n",
    "subject:  Orthogonality\n",
    "subtitle: \n",
    "short_title: Orthogonal Matrices\n",
    "authors:\n",
    "  - name: Nikolai Matni\n",
    "    affiliations:\n",
    "      - Dept. of Electrical and Systems Engineering\n",
    "      - University of Pennsylvania\n",
    "    email: nmatni@seas.upenn.edu\n",
    "license: CC-BY-4.0\n",
    "keywords: Orthogonal Matrix, QR Decomposition\n",
    "math:\n",
    "  '\\vv': '\\mathbf{#1}'\n",
    "  '\\bm': '\\begin{bmatrix}'\n",
    "  '\\em': '\\end{bmatrix}'\n",
    "  '\\R': '\\mathbb{R}'\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading\n",
    "\n",
    "Material related to this page, as well as additional exercises, can be found in ALA 4.3.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this page, you should know:\n",
    "- What is an orthogonal matrix?\n",
    "- What is the QR decomposition of a square matrix?\n",
    "- How can we use the QR decomposition to solve systems of equatitons of the form $A\\vv{x} = \\vv b$, with $A$ square?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orthogonal Matrices\n",
    "\n",
    "Rotations and reflections play key roltes in geomtry, physics, robotics, quantum mechanics, airplans, compute graphics, data science, and more. These transformations are encoded via *orthogonal matrices*, that is matirces whose columns form an orthonormal basis for $\\mathbb{R}^n$. They also play a centrla role in one of the most important methods of linear algebra, the *QR decomposition*.\n",
    "\n",
    "We start with a definition.\n",
    "\n",
    ":::{prf:definition} Orthogonal Matrix\n",
    ":label: orthogonal-matrix-defn\n",
    "\n",
    "A square matrix $Q$ is called *orthogonal* if it satisfies \n",
    "\n",
    "\\begin{align*}\n",
    "    QQ^{\\top} = Q^{\\top}Q = I.\n",
    "\\end{align*}\n",
    "\n",
    "This means that $Q^{-1} = Q^{\\top}$ (in fact, we could define orthogonal matrices this way instead), and that solving linear systems of the form $Q\\vv x = \\vv b$ is very easy: simply set $\\vv x = Q^\\top \\vv b$!\n",
    "\n",
    "Notice that $Q^\\top Q = I$ implies that the columns of $Q$ are orthonormal. If $Q = [\\vv{q_1}, ..., \\vv{q_n}]$, then \n",
    "\n",
    "\\begin{align*}\n",
    "    (Q^\\top Q)_{ij} = \\vv{q_i}^\\top \\vv{q_j} = I_{ij} = \\begin{cases} 1 \\quad\\text{if $i \\neq j$}\\\\ 0\\quad\\text{if $i = j$}\\end{cases}\n",
    "\\end{align*}\n",
    "\n",
    "which is exactly the definition of an orthonormal collcetion of vectors. Further, since ther eare $n$ such vectors, they must form an [orthonormal basis](#orthonormal-basis-defn) for $\\mathbb{R}^n$. \n",
    ":::\n",
    "\n",
    "Now, let's explore some of the consequences of this definition.\n",
    "\n",
    ":::{prf:example} $2 \\times 2$ orthogonal matrices\n",
    ":label: orthogonal-matrices-ex1\n",
    "\n",
    "A $2\\times 2$ matric $Q = \\bm a&b\\\\c&d\\em$ is orthogonal if and only if\n",
    "\n",
    "\\begin{align*}\n",
    " Q^\\top Q = \\bm a^2 + c^2 & ab + cd \\\\ ac + cd & b^2 + d^2\\em = \\bm 1\\\\ 0\\\\ 0\\\\ 1\\em \n",
    "\\end{align*}\n",
    "\n",
    "or equivalently\n",
    "\n",
    "\\begin{align*}\n",
    "    a^2 + c^2 = 1, \\quad ab + cd = 0, \\quad b^2 + d^2 = 1\n",
    "\\end{align*}\n",
    "\n",
    "The first and last equations say that $\\bm a\\\\ c \\em$ and $\\bm b\\\\ d \\em$ lie on the unit circle in $\\mathbb{R}^2$: a convenient and revealing way of writing this is by setting\n",
    "\n",
    "\\begin{align*}\n",
    "    a = \\cos \\theta, \\quad c= \\sin \\theta, \\quad b = \\cos \\phi, \\quad d = \\sin \\phi\n",
    "\\end{align*}\n",
    "\n",
    "since $\\cos^2 \\theta + \\sin^2\\theta = 1$ for all $\\theta \\in \\mathbb{R}$.\n",
    "\n",
    "Our last condition is $0 = ad + cd = \\cos\\theta \\cos \\phi +\\sin\\theta \\sin\\phi = \\cos(\\theta - \\phi)$. Now \n",
    "\\begin{align*}\n",
    "    \\cos (\\theta - \\phi) = 0 &\\iff \\theta - \\phi = \\frac{\\pi}{2} + 2 n \\pi\\quad \\text{or} \\quad \\theta - \\phi = -\\frac{\\pi}{2} \\\\\n",
    "    &\\iff \\pi = \\theta \\pm \\frac{\\pi}{2} \n",
    "\\end{align*}\n",
    "\n",
    "This means either:\n",
    "\n",
    "* $b = -\\sin\\theta$ and $d = \\cos\\theta$ \n",
    "\n",
    "* or $b = \\sin\\theta$ and $d = -\\cos \\theta$\n",
    "\n",
    "As a result, every $2\\times 2$ orthogonal matrix has one of two possible forms:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\bm \\cos\\theta & -\\sin\\theta \\\\ \\sin\\theta & \\cos\\theta \\em \\quad\\text{or}\\quad \\bm \\cos\\theta & \\sin\\theta \\\\ \\sin\\theta & -\\cos\\theta \\em\n",
    "\\end{align*}\n",
    "\n",
    "where by convention, we restrict $\\theta \\in [0, 2\\pi)$.\n",
    "\n",
    "The columns of both matrices form an orthonormal basis for $\\mathbb{R}^2$. The first is obtained by rotating the [standard basis](#basis_eg) $\\vv{e_1}, \\vv{e_2}$ through angle $\\theta$, the second by first reflexting about the x-axis and the rotating.\n",
    "\n",
    "![Orthogonal matrices in $\\mathbb{R}^2$](../figures/04-orthogonal_matrix.png)\n",
    "\n",
    ":::\n",
    "\n",
    "If we think about the map $\\vv x \\mapsto Q \\vv x$ defined by multiplication with an orthogonal matrix as rotating and/or reflectingthe vector $\\vv x$, then the following property should not be surprising:\n",
    "\n",
    ":::{important}\n",
    "The product of two orthogonal matrices is also orthogonal!\n",
    ":::\n",
    "\n",
    "Before grinding through some algebra, let's think about this through the lens of rotation and reflections. Multiply $\\vv x$ by a product of orthogonal matrices $Q_2Q_1$ is the same as first rotation/reflecting $\\vv x$ by $Q_1$ to obtain $Q_1 \\vv x$, and then rotating/reflecting $Q_1 \\vv x$ by $Q_2$ to get $Q_2 Q_1 \\vv x$. Now a sequence of rotations and reflections is still ultimately a rotation and/or reflection so we must have $Q_2 Q_1 \\vv x = Q \\vv x$ for some orthogonal $Q = Q_2 Q_1$.\n",
    "\n",
    "Let's check that this intuition carries over in the math. Since $Q_1$ and $Q_2$ are orthogonal, we have that\n",
    "\n",
    "\\begin{align*}\n",
    "    Q^\\top_1 Q_1 = I = Q_2^\\top Q_2.\n",
    "\\end{align*}\n",
    "\n",
    "Let's check that $(Q_1Q_2)^\\top (Q_1Q_2) = I$:\n",
    "\n",
    "\\begin{align*}\n",
    "    (Q_1Q_2)^\\top (Q_1Q_2) = Q_2^\\top \\underbrace{Q_1^\\top Q_1}_{I}Q_2 = \\underbrace{Q_2^\\top Q_2}_I = I\n",
    "\\end{align*}\n",
    "\n",
    "Therefore $(Q_1 Q_2)^{-1} = (Q_1 Q_2)^\\top$, and we indeed have $Q_1Q_2$ is orthogonal.\n",
    "\n",
    ":::{important}\n",
    "\n",
    "This multiplicative property combined with the fact that the inverse of an orthogonal matrix is orthogonal (why?) says that the set of all orthogonal matrices (of dimension $n$) forms a *group* (under matrix multiplication). \n",
    "\n",
    "Group theory underlies much of modern physics and quantum mechanics and plays a central role in robotics. Although we will not spend too much time on groups in this class, you are sure to see them again in the future. \n",
    "\n",
    "The aforementioned *orthogonal group* in particular is central to rigid body mechanics, atomic structure and chemistry, and computer graphics, among many other applications.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The QR Factorization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
