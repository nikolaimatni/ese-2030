{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: 8.1 Linear Iterative Systems\n",
    "subject:  Iteration\n",
    "subtitle: discrete time systems\n",
    "short_title: 8.1 Linear Iterative Systems\n",
    "authors:\n",
    "  - name: Nikolai Matni\n",
    "    affiliations:\n",
    "      - Dept. of Electrical and Systems Engineering\n",
    "      - University of Pennsylvania\n",
    "    email: nmatni@seas.upenn.edu\n",
    "license: CC-BY-4.0\n",
    "keywords: \n",
    "math:\n",
    "  '\\vv': '\\mathbf{#1}'\n",
    "  '\\bm': '\\begin{bmatrix}'\n",
    "  '\\em': '\\end{bmatrix}'\n",
    "  '\\R': '\\mathbb{R}'\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/nikolaimatni/ese-2030/HEAD?labpath=/07_Ch_8_Iteration/091-Linear_Iterative_Systems.ipynb)\n",
    "\n",
    "{doc}`Lecture notes <../lecture_notes/Lecture 15 - Linear Iterative Systems, Matrix Powers, Markov Chains, and Googleâ€™s PageRank.pdf>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading\n",
    "\n",
    "Material related to this page, as well as additional exercises, can be found in ALA 9.1.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this page, you should know:\n",
    "- the stable behavior of _discrete time_ scalar system \n",
    "- the definition of a general linear iterative system\n",
    "- the general solution to linear iterative systems using eigenvectors\n",
    "- how to compute the general solution using diagonalization and iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete Time System\n",
    "\n",
    "So far, we have focused on _continuous time_ dynamical systems, for which the \n",
    "time index $t$ of the solution $\\vv x(t)$ is continuous, i.e., $t \\in \\mathbb{R}$. This is a natural model to use for many systems, such as for example those evolving according to the \n",
    "laws of physics. However, in other instances, it is more natural to consider time in _discrete_ steps. For example, when banks add interest to a savings account, they typically do so on a monthly or yearly basis. More specifically, suppose at period $k$, we have $x(k)$ dollars in our \n",
    "account, and an interest rate of $r$ is applied. Then $x(k+1) = (1+r)x(k)$. This defines a _scalar linear iterative system_, whichtake the general form\n",
    "\n",
    "\\begin{equation}\n",
    "\\label{sc_lin_iter}\n",
    "x(k+1) = \\lambda x(k), \\quad x(0) = a.\n",
    "\\end{equation}\n",
    "\n",
    "If we _roll out_ the dynamics [](#sc_lin_iter), we easily compute:\n",
    "\n",
    "$$\n",
    "x(0) &= a, \\\\\n",
    "x(1) &= \\lambda a, \\\\\n",
    "x(2) &= \\lambda^2 a, \\\\\n",
    "&\\ldots \\\\\n",
    "x(k) &= \\lambda^k a \\quad \\text{for any positive integer } k.\n",
    "$$\n",
    "\n",
    "We therefore immediately conclude that there are three possibilities for $x(0) = a \\neq 0$:\n",
    "- **Stable**: If $|\\lambda| < 1$, then $|x(k)| \\to 0$ as $k \\to \\infty$\n",
    "- **Marginally Stable**: If $|\\lambda| = 1$, then $|x(k)| = |a|$ for all $k \\in \\mathbb{N}$, where $\\mathbb{N} = \\{0, 1, 2, \\ldots, \\ldots \\}$ (non-negative integers)\n",
    "- **Unstable**: If $|\\lambda| > 1$, then $|x(k)| \\to \\infty$ as $k \\to \\infty$\n",
    "\n",
    "Our goal is to extend this analysis to the general _linear iterative systems_, that is formally defined below.\n",
    "\n",
    ":::{prf:definition} Linear Iterative System\n",
    ":label: lin_iter_defn\n",
    "A _linear iterative system_ takes the form\n",
    "\\begin{equation}\n",
    "\\label{lin_iter_eqn}\n",
    "\\vv x(k+1) = T \\vv x(k), \\quad \\vv x(0) = a,\n",
    "\\end{equation}\n",
    "\n",
    "where $\\vv x(k) \\in \\mathbb{R}^n$ and $T \\in \\mathbb{R}^{n \\times n}$ is the _coefficient matrix_. \n",
    ":::\n",
    "\n",
    "We will then use these tools to study a very important class of linear iterative systems called _Markov Chains_, which can be used for everything from internet search (Google's search algorithm PageRank) to baseball statistics (DraftKings uses these ideas to set betting odds!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Powers of Matrices\n",
    "\n",
    "Rolling out the dynamics [](#lin_iter_eqn), we again see a clear solution to [](#lin_iter_eqn):\n",
    "\n",
    "$$\n",
    "\\vv x(0) &= \\vv a, \\\\\n",
    "\\vv x(1) &= T \\vv a, \\\\\n",
    "\\vv x(2) &= T^2 \\vv a, \\\\\n",
    "&\\ldots \\\\\n",
    "\\vv x(k) &= T^k \\vv a \\quad \\text{for all } k \\in \\mathbb{N}.\n",
    "$$\n",
    "\n",
    "However, unlike the scalar setting [](#sc_lin_iter), the qualitative behavior of $\\vv x(k) = T^k \\vv a$ as $k \\to \\infty$ is much less obvious. Since the scalar solution $x(k) = \\lambda^k a$ is defined in terms of powers of $\\lambda$, let's try a similar guess for the vector-valued \n",
    "setting: $\\vv x(k) = \\lambda^k \\vv v$. Under what conditions on $\\lambda$ and $\\vv v$ is $\\vv x(k) = \\lambda^k \\vv v$ a solution to [](#lin_iter_eqn)?\n",
    "On one hand, we have that $\\vv x(k+1) = \\lambda^{k+1} \\vv v$. On the other, we have\n",
    "$$\n",
    "T\\vv x(k) = T(\\lambda^k \\vv v) = \\lambda^k T\\vv v.\n",
    "$$\n",
    "\n",
    "The expressions $\\vv x(k+1) = \\lambda^{k+1} \\vv v$ and $T\\vv x(k) = \\lambda^k T\\vv v$ will be equal if and only if $T \\vv v = \\lambda \\vv v$, i.e., if and  only if $(\\lambda, \\vv v)$ is an eigenvalue/vector pair of $T$.\n",
    "\n",
    "Thus, for each eigenvalue/vector pair $(\\lambda_i, \\vv v_i)$ of $T$, we can construct a solution $\\vv x_i(k) = \\lambda_i^k \\vv v_i$ to [](#lin_iter_eqn). By linear superposition, we can use \n",
    "this observation to characterize all solutions for complete matrices.\n",
    "\n",
    ":::{prf:theorem} The solution to a linear iterative system with complete coefficient matrix\n",
    ":label: pow_mat_thm\n",
    "If the coefficient matrix $T$ is complete (i.e., diagonalizable), then the general solution to the linear iterative system $\\vv x(k+1) = T\\vv x(k)$ is given by\n",
    "\n",
    "$$\n",
    "\\vv x(k) = c_1 \\lambda_1^k \\vv v_1 + c_2 \\lambda_2^k \\vv v_2 + \\cdots + c_n \\lambda_n^k \\vv v_n,\n",
    "$$\n",
    "\n",
    "where $\\vv v_1, \\ldots, \\vv v_n$ are linearly independent eigenvectors of $T$ with corresponding \n",
    "eigenvalues $\\lambda_1, \\ldots, \\lambda_n$, and coefficients $c_1, \\ldots, c_n$ are scalars uniquely prescribed  by the initial condition\n",
    "$$\n",
    "\\vv x(0) = \\bm \\vv v_1  & \\vv v_2 & \\cdots & \\vv v_n \\em \\vv c = \\vv a.\n",
    "$$\n",
    ":::\n",
    "\n",
    "We can extend [this theorem](#pow_mat_thm) to incomplete matrices using Jordan Blocks, but \n",
    "the idea remains the same.\n",
    "\n",
    "::::{prf:example} \n",
    ":label: eg_1\n",
    "Consider the iterative system $\\vv x(k+1) = T\\vv x(k)$ defined by\n",
    "$$\n",
    "\\bm x_1(k+1) \\\\ x_2(k+1) \\em = \\bm .6 & .2 \\\\ .2 & .6 \\end{bmatrix} \\bm x_1(k) \\\\ x_2(k) \\em, \\quad \\bm x_1(0) \\\\ x_2(0) \\em = \\bm a_1 \\\\ a_2 \\em.\n",
    "$$\n",
    "\n",
    "$T$ has eigenvalue/vector pairs:\n",
    "\n",
    "$$\n",
    "\\lambda_1 = .8, \\ \\vv v_1 = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} \\quad \\text{and} \\quad \\lambda_2 = .4, \\; \\vv v_2 = \\begin{bmatrix} -1 \\\\ 1 \\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "Therefore, the eigensolutions are\n",
    "$$\n",
    "\\vv x_1(k) = \\lambda_1^k \\vv v_1 = (.8)^k \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} \\quad \\text{and} \\quad \\vv x_2(k) = \\lambda_2^k \\vv v_2 = (.4)^k \\begin{bmatrix} -1 \\\\ 1 \\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "Thus, a general solution is given by \n",
    "$$\\vv x(k) = c_1 \\vv x_1(k) + c_2 \\vv x_2(k) = c_1(.8)^k \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} + c_2(.4)^k \\begin{bmatrix} -1 \\\\ 1 \\end{bmatrix}$$\n",
    "\n",
    "To determine $c_1$ and $c_2$, we solve \n",
    "$$\n",
    "\\vv x(0) = \\begin{bmatrix} c_1 - c_2 \\\\ c_1 + c_2 \\end{bmatrix} = \\begin{bmatrix} a_1 \\\\ a_2 \\end{bmatrix} \\Rightarrow c_1 = \\frac{a_1+a_2}{2}, \\ c_2 = \\frac{a_2-a_1}{2}\n",
    "$$\n",
    "\n",
    "giving the specific solution\n",
    "$$\n",
    "\\bm x_1(k) \\\\ x_2(k) \\em =  \\frac{a_1 + a_2}{2}(.8)^k \\bm 1 \\\\ 1 \\em + \n",
    "\\frac{a_2 - a_1}{2}(.4)^k \\bm -1 \\\\ 1 \\em.\n",
    "$$\n",
    "\n",
    "We conclude that $\\vv x(k) \\to 0$ as $k \\to \\infty$, and that the slowest decaying direction is $\\vv v_1 = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$, which decays at rate $0.8$ (gets 20% smaller) each time step. We can visualize this in the plot below; we sampled initial conditions along the unit circle (shown in orange) and plotted the iterates after 0, 1, 2, 3, 4 (corresponding to orange, green, blue, purple, red respectively) time steps.\n",
    "\n",
    ":::{figure}../figures/08-stable_iter_sys.jpg\n",
    ":label:stable_iter_sys\n",
    ":alt:Stable Iterative Systems\n",
    ":width: 350px\n",
    ":align: center\n",
    ":::\n",
    "\n",
    "::::\n",
    "\n",
    ":::{prf:example} Solving a $3\\times 3$ linear iterative system (ALA Example 9.7)\n",
    ":label: linear-iterative-ex1\n",
    "\n",
    "Let $T = \\bm -3&1&6\\\\1&-1&-2\\\\-1&-1&0\\em$ be the coefficient matrix for a three-dimensional iterative system $\\vv{u}(k + 1) = T\\vv u(k)$. Its eigenvalues and corresponding eigenvectors are\n",
    "\n",
    "$$\n",
    "\\begin{array}{ccc}\n",
    "\\lambda_1 = -2, & \\lambda_2 = -1 + i, & \\lambda_3 = -1 -i,\\\\\n",
    "\\vv{v_1} = \\bm 4\\\\-2\\\\1\\em, & \\vv{v_2} = \\bm 2 - i \\\\ -1 \\\\ 1 \\em, & \\vv{v_3} = \\bm 2 + i \\\\ -1 \\\\ 1\\em.\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "These eigenvectors are linearly independent and hence $T$ is complete. Applying the above result on linear iterative systems with complete coefficient matrices, the general complex solution to this is \n",
    "\n",
    "$$\n",
    "\\vv{u}(k) = v_1(-2)^k \\bm 4\\\\-2\\\\1\\em + b_2 (-1 + i)^k\\bm 2-i\\\\-1\\\\1\\em + b_3 (-1 - i)^k\\bm 2 + i\\\\-1\\\\1\\em\n",
    "$$\n",
    "\n",
    "where $b_1, b_2, b_3$ are complex scalars corresponding to the choice of initial condition $\\vv u(0)$.\n",
    "\n",
    "If we are only interested in real solutions (e.g., if the initial conditions are real), we can break up any complex solution into its real and imaginary parts, each of which constitutes a real solution.  We begin by writing $\\lambda_2 = -1 + i = \\sqrt 2 (\\cos{\\frac 3 4 \\pi} + i\\sin{\\frac 3 4 \\pi}) = \\sqrt 2 e^{3\\pi i/4}$ in polar form, and hence (applying [Euler's formula](#euler-formula-thm)),\n",
    "\n",
    "$$\n",
    "(-1 + i)^k =  (\\sqrt 2) ^ke^{\\frac 3 4 k\\pi i} = (\\sqrt 2) ^k (\\cos {\\frac 3 4 k \\pi} + i \\sin {\\frac 3 4 k \\pi}).\n",
    "$$\n",
    "\n",
    "Therefore, the complex solution corresponding to $\\lambda_2 = -1 + i$ can be rewritten as\n",
    "\n",
    "$$\n",
    "(-1 + i)^k\\bm 2 - i\\\\ -1\\\\1\\em = (\\sqrt 2)^k \\bm 2\\cos {\\frac 3 4 k \\pi} + \\sin {\\frac 3 4 k \\pi} \\\\ -\\cos {\\frac 3 4 k \\pi} \\\\ \\cos{\\frac 3 4 k \\pi}\\em + i (\\sqrt 2)^k \\bm 2\\sin{\\frac 3 4 k \\pi} - \\cos{\\frac 3 4 k \\pi} \\\\ -\\sin {\\frac 3 4 k \\pi} \\\\ \\sin{\\frac 3 4 k\\pi} \\em\n",
    "$$\n",
    "\n",
    "can be rewritten as a (complex) combination of two linearly independent real solutions! We do the same for the complex conjugate eigenvalue $\\lambda_3 = -1 -i$, which leads to the complex conjugate solution and the same two real solutions:\n",
    "\n",
    "$$\n",
    "(-1 - i)^k\\bm 2 + i\\\\ -1\\\\1\\em = (\\sqrt 2)^k \\bm 2\\cos{\\frac 3 4 k \\pi} + \\sin{\\frac 3 4 k \\pi}\\\\-\\cos{\\frac 3 4 k \\pi} \\\\ \\cos{\\frac 3 4 k \\pi} \\em - i (\\sqrt 2)^k \\bm 2\\sin{\\frac 3 4 k \\pi} - \\cos{\\frac 3 4 k \\pi} \\\\ -\\sin {\\frac 3 4 k \\pi} \\\\ \\sin{\\frac 3 4 k\\pi} \\em\n",
    "$$\n",
    "\n",
    "\n",
    "Note that this is incredibly similar to our approach for rewriting complex solutions to linear ODEs! We take the complex base solutions, and use Euler's identity to rewrite them as (complex) linear combinations of real solutions! Thus, the general real solution $\\vv{u}(k)$ to the system can be written as a linear combination of the three independent real solutions:\n",
    "\n",
    "$$\n",
    "c_1 (-2)^k \\bm 4\\\\-2\\\\1\\em + c_2 (\\sqrt 2)^k \\bm 2\\cos {\\frac 3 4 k \\pi} + \\sin {\\frac 3 4 k \\pi} \\\\ -\\cos {\\frac 3 4 k \\pi} \\\\ \\cos{\\frac 3 4 k \\pi}\\em + c_3 (\\sqrt 2)^k \\bm 2\\sin{\\frac 3 4 k \\pi} - \\cos{\\frac 3 4 k \\pi} \\\\ -\\sin {\\frac 3 4 k \\pi} \\\\ \\sin{\\frac 3 4 k\\pi} \\em\n",
    "$$\n",
    "\n",
    "where $c_1, c_2, c_3$ are arbitrary real scalars (assuming that the initial conditions are real), uniquely prescribed by the initial conditions.\n",
    "\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagonalization and Iteration\n",
    "\n",
    "An alternative and equally efficient approach to solving [](#lin_iter_eqn) in the case of complex matrices is based on the diagonalization of T. We start with the following observation (which we also saw when computing the matrix exponential). Let $V = \\bm \\vv v_1 & \\cdots & \\vv v_n\\em$ be an eigenbasis for $T$, and $\\Lambda = \\text{diag}(\\lambda_1, \\ldots, \\lambda_n)$ the diagonal matrix of the eigenvalues of $T$. Then:\n",
    "\n",
    "\\begin{align*}\n",
    "T &= V \\Lambda V^{-1} \\\\\n",
    "T^2 &= V \\Lambda V^{-1} V \\Lambda V^{-1} = V \\Lambda^2 V^{-1} \\\\\n",
    "T^3 &= T(T^2) = V \\Lambda V^{-1} V \\Lambda^2 V^{-1} = V \\Lambda^3 V^{-1}\n",
    "\\end{align*}\n",
    "\n",
    "and in general, $T^k = V \\Lambda^k V^{-1}$. Therefore, the solution to $\\vv x(k+1) = T\\vv x(k)$, with $\\vv x(0) = \\vv a$ is\n",
    "$$\n",
    "\\vv x(k) = T^k \\vv a = V \\Lambda^k V^{-1} \\vv a. \n",
    "$$\n",
    "\n",
    "If we define $\\vv c = V^{-1}\\vv a$, then we recover $\\vv x(k) = c_1 \\lambda_1^k \\vv v_1 + \\cdots + c_n \\lambda_n^k \\vv v_n$.\n",
    "\n",
    ":::{prf:example} Solving a $2\\times 2$ linear iterative system with diagonalization\n",
    ":label: linear-iterative-ex2\n",
    "\n",
    "Let $T = \\bm 7&6\\\\-9&-8\\em$. Its eigenvalues and eigenvectors are:\n",
    "\n",
    "$$\n",
    "\\lambda_1 = -2, \\quad \\vv{v_1} = \\bm -2\\\\3\\em, \\qquad \\lambda_2 = 1, \\quad \\vv{v_2} = \\bm -1\\\\1\\em.\n",
    "$$\n",
    "\n",
    "We assemble these into the diagonal eigenvalue matrix $S$ and the eigenvector matrix $P$, given by\n",
    "\n",
    "$$\n",
    "D = \\bm -2 &0\\\\0&1\\em, \\qquad P = \\bm -2&-1\\\\3&1\\em,\n",
    "$$\n",
    "\n",
    "such that a [diagonalization](#diagonalizable-defn) of $T$ is given by $T = PDP^{-1}$. Therefore, using the results above, \n",
    "\n",
    "$$\n",
    "T^k = PD^kP^{-1} &= \\bm -2&-1\\\\3&1\\em \\bm (-2)^k &0\\\\0&1 \\em \\bm 1&1\\\\-3&-2\\em\\\\\n",
    "&= \\bm 3-2(-2)^k & 2 -2(-2)^k\\\\-3 + 3(-2)^k&-2 + 3(-2)^k \\em.\n",
    "$$\n",
    "\n",
    "It follows that the solution to the particular iterative system with coefficient matrix $T$ and initial conditions $\\vv u(0)$ is given by\n",
    "\n",
    "$$\n",
    "\\vv u(k) = T^k \\vv u(0) = \\bm 3-2(-2)^k & 2 -2(-2)^k\\\\-3 + 3(-2)^k&-2 + 3(-2)^k \\em\\vv u(0).\n",
    "$$\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/nikolaimatni/ese-2030/HEAD?labpath=/07_Ch_8_Iteration/091-Linear_Iterative_Systems.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
