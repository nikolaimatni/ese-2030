{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: 6.2 Determinants\n",
    "subject:  Determinants\n",
    "subtitle: \n",
    "short_title: 6.2 Determinants\n",
    "authors:\n",
    "  - name: Nikolai Matni\n",
    "    affiliations:\n",
    "      - Dept. of Electrical and Systems Engineering\n",
    "      - University of Pennsylvania\n",
    "    email: nmatni@seas.upenn.edu\n",
    "license: CC-BY-4.0\n",
    "keywords: Determinants\n",
    "math:\n",
    "  '\\vv': '\\mathbf{#1}'\n",
    "  '\\bm': '\\begin{bmatrix}'\n",
    "  '\\em': '\\end{bmatrix}'\n",
    "  '\\R': '\\mathbb{R}'\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/nikolaimatni/ese-2030/HEAD?labpath=/03_Orthogonality/053-orthogonal_matrices.ipynb)\n",
    "\n",
    "{doc}`Lecture notes <../lecture_notes/Lecture 11 - Eigvenvalues and Eigenvectors part 1 (dynamical systems, determinants, basic definitions and computations).pdf>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading\n",
    "\n",
    "Material related to this page, as well as additional exercises, can be found in ALA 1.9.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this page, you should know:\n",
    "- some key facts of the determinant,\n",
    "- several ways to find the determinant of a matrix,\n",
    "- (optional) the formal definition of a determinant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determinants\n",
    "\n",
    "We assume that you have already seen determinants in Math 1410, and focus here on reviewing the  key properties. Before proceeding, we pause to note that determinants have very deep meanings, especially in differential calculus, as they keep track of volumes as they are transformed via (linear or otherwise) functions. They are indeed very useful theoretical tools, but much like matrix inverses, are rarely computed by hand, except for $2 \\times 2$ cases. Below is a helpful link if you need a refresher on the determinant.\n",
    "\n",
    "* [Math 1410 video lecture (geometric interpretation of the determinant for small matrices)](https://www.youtube.com/watch?v=6hXxrbnbtC4)\n",
    "\n",
    "## Key Properties of the Determinant\n",
    "\n",
    "First, we'll state a couple of key facts about the determinant.\n",
    "\n",
    "\n",
    ":::{prf:definition} Key Properties of the Determinant\n",
    ":label: determinant-properties-defn\n",
    "\n",
    "1. The determinant of a matrix $A$, written $\\det A$ or $|A|$, is only defined if $A$ is square.\n",
    "\n",
    "2. The determinant of a $1\\times 1$ matirx $A = [a]$ is $\\det [a] = a$. The determinant of a $2 \\times 2$ matrix is $\\det \\bm a & b\\\\ c & d \\em= ad - bc$. You may recognize this expression from our formula for the inverse of a $2\\times 2$ matrix:\n",
    "\\begin{align*}\n",
    "\\bm a & b\\\\c&d \\em^{-1} = \\frac{1}{ad -bc}\\bm d&-b\\\\-c&a \\em.\n",
    "\\end{align*}\n",
    "\n",
    "In this case, $\\bm a & b\\\\c&d \\em^{-1}$ exists if and only if $\\det \\bm a & b\\\\c&d \\em = ad - bc \\neq 0$. This observation is true in general:\n",
    "\n",
    "3. $A^{-1}$ exists, i.e., $A$ is nonsingular, if and only if, $\\det A \\neq 0$.\n",
    "\n",
    "A corollary of Fact 3, which we will use in our eigenvalue computations, is that $A$ is singular if and only if $\\det A = 0$.\n",
    "\n",
    "4. If $U$ is a block upper diagonal matrix, i.e., if $U = \\bm U_{11} & U_{12} \\\\ 0 & U_{22}\\em$ for $U_{ij}$ of compatible dimension, then $\\det U = \\det{U_{11}} \\cdot\\det{U_{22}}$, i.e., the determinant of $U$ is given by the products of the determinants of its block diagonals.\n",
    "\n",
    "5. The determinant of a matrix is equal to the determinant of its transpose, $\\det A = \\det A^\\top$.\n",
    "\n",
    ":::\n",
    "\n",
    "These facts are all we need for now to get started finding eigenvalues.\n",
    "\n",
    "## Optional: An Algebraic Definition of the Determinant\n",
    "\n",
    "Other than for computing eigenvalues, we don't really spend much time working with determinants in this course. However, for interested students, we will give an algebraic definition of the determinant as well as some methods of finding the determinant of a matrix. This definition is taken from [these notes](https://public.websites.umich.edu/~willdana/Determinant%20Notes.pdf), which explain the connection between the geometric and algebraic interpretations of the determinant.\n",
    "\n",
    ":::{prf:definition} The Determinant of a Matrix\n",
    ":label: determinant-defn\n",
    "\n",
    "The determinant is the unique alternating, multilinear map $\\det : \\mathbb{R}^n \\to\\mathbb R$ defined on the columns of a matrix which is equal to $1$ when given the standard basis vectors in order. The determinant of a matrix $A$ with columns $a_1, a_2, \\dots, a_n$ is denoted as $|A| = \\det A = \\det(a_1, a_2, \\dots, a_n)$.\n",
    "\n",
    "* A *multilinear* function is a function which, when keeping all of the arguments except one constant, is linear in the last argument, i.e., \n",
    "\n",
    "\\begin{align*}\n",
    "&\\det(\\vv a_1, \\dots, \\vv a_{i - 1}, \\vv a_i + \\vv b_i, \\vv a_{i + 1}, \\dots, \\vv a_n) \\\\\n",
    "&= \\det(\\vv a_1, \\dots, \\vv a_{i - 1}, \\vv a_i, \\vv a_{i + 1}, \\dots, \\vv a_n) + \\det(\\vv a_1, \\dots, \\vv a_{i - 1}, \\vv b_i, \\vv a_{i + 1}, \\dots, \\vv a_n)\n",
    "\\end{align*}\n",
    "\n",
    "(A familiar special case of multilinearity is bilinearity, which is satisfied by [inner products](#inner_defn).)\n",
    "\n",
    "* An *alternating* function is a function whose output is negated after swapping two of its arguments, i.e.,\n",
    "\n",
    "\\begin{align*}\n",
    "&\\det(\\vv a_1, \\dots, \\vv a_{i}, \\dots, \\vv a_{j}, \\dots, \\vv a_n) \\\\\n",
    "&= -\\det(\\vv a_1, \\dots, \\vv a_{j}, \\dots, \\vv a_{i}, \\dots, \\vv a_n)\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "* The last condition, that the determinant is equal to $1$ when given the standard basis vectors in order, is equivalent to the statement\n",
    "\n",
    "\\begin{align*}\n",
    "\\det I = 1\n",
    "\\end{align*}\n",
    "\n",
    "where $I$ is the identity matrix.\n",
    "\n",
    "* Finally, these properties uniquely define the determinant; any function satisfying the above 3 properties must be the determinant function.\n",
    ":::\n",
    "\n",
    "From this definition, we can compute the determinants of the elementary matrices!\n",
    "\n",
    ":::{prf:theorem} Determinants of elementary matrices\n",
    ":label: elementary-det-thm\n",
    "\n",
    "Recall the three types of [elementary matrices](#elementary), corresponding to row addition, row swapping, and row scaling. The determinants of these elementary matrices are as follows:\n",
    "\n",
    "* The determinant of an elementary matrix corresponding to a row addition (e.g., $\\bm 1&0&0\\\\2&1&0\\\\0&0&1\\em$, which adds $2$ times the first row to the second) is $1$. \n",
    "\n",
    "* The determinant of an elementary matrix corresponding to switching two rows (e.g., $\\bm 1&0&0\\\\0&0&1\\\\0&1&0\\em$) is $-1$.\n",
    "\n",
    "* The determinant of an elementary matrix corresponding to scaling a row by a factor of $c$ (e.g., $\\bm 3&0&0\\\\0&1&0\\\\0&0&1\\em$) is $c$. \n",
    ":::\n",
    "\n",
    "To see why, note that the determinants of scaling and switching follow immediately from the multilinear and alternating properties of the determinant, respectively. To prove that the determinant of a row addition matrix is $1$, we'll show this is the case for a specific elementary matrix, and then you should convince yourself this is true for all row addition matrices:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\det \\bm 1&0&0\\\\2&1&0\\\\0&0&1\\em &= \\det \\bm 1&0&0\\\\0&1&0\\\\0&0&1\\em + \\det \\bm 0&0&0\\\\2&1&0\\\\0&0&1\\em \\quad\\text{(multilinearity)}\\\\\n",
    "    &= 1 + \\bm 0&0&0\\\\2&1&0\\\\0&0&1\\em  \\quad\\text{(determinant of identity is $1$)}\\\\\n",
    "    &= 1 + 2\\bm 0&0&0\\\\1&1&0\\\\0&0&1\\em  \\quad\\text{(multilinearity)}\\\\\n",
    "\\end{align*}\n",
    "\n",
    "Using the alternating property, you can show that $\\det \\bm 0&0&0\\\\1&1&0\\\\0&0&1\\em = 0$. Therefore, we have that $\\det \\bm 1&0&0\\\\2&1&0\\\\0&0&1\\em = 1$.\n",
    "\n",
    "Equipped with these results, we can see how right multiplying by an elementary matrix changes the determinant. Recall that right multiplication by an elementary matrix defines a column operation; we'll also extend these results to left multiplication by an elementary matrix (which defines a row operation).\n",
    "\n",
    ":::{prf:theorem} Determinant after an elementary operation\n",
    ":label: elementary-op-det-thm\n",
    "\n",
    "Let $E_1, E_2, E_3$ be elementary matrices corresponding to addition, swapping, and scaling, respectively. Then, for any square matrix $A$:\n",
    "\n",
    "* Right multiplication by $E_1$ preserves the determinant: $\\det AE_1 = \\det A$.\n",
    "\n",
    "* Right multiplication by $E_2$ negates the determinant: $\\det AE_2 = -\\det A$. \n",
    "\n",
    "* Right multiplication by $E_3$ (where $E_3$ scales by a factor of $c$) scales the determinant: $\\det AE_1 = c \\det A $. \n",
    "\n",
    "In particular, we are beginning to work towards one of the most important properties of the determinant. For now, note that $\\det AE = \\det A \\det E$ for any elementary matrix $E$! In fact, we can immediately use this result, and the commutativity of multiplication, to show that:\n",
    "\n",
    "\\begin{align*}\n",
    "\\det AE = \\det A \\det E = \\det E \\det A = \\det EA\n",
    "\\end{align*}\n",
    "\n",
    "In other words:\n",
    "\n",
    "* Left multiplication by $E_1$ preserves the determinant: $\\det AE_1 = \\det A$.\n",
    "\n",
    "* Left multiplication by $E_2$ negates the determinant: $\\det AE_2 = -\\det A$. \n",
    "\n",
    "* Left multiplication by $E_3$ (where $E_3$ scales by a factor of $c$) scales the determinant: $\\det AE_1 = c \\det A $. \n",
    "\n",
    "So we've characterized how elementary row and column operations affect the determinant!\n",
    ":::\n",
    "\n",
    "The proof of these properties is not hard, and follows from a few applications of the defining properties of the determinant. Try to prove these yourself! \n",
    "\n",
    "Now, we are ready to prove a lot of useful facts about determinants! We'll state and prove them one by one.\n",
    "\n",
    ":::{prf:theorem} Determinant of a triangular matrix\n",
    ":label: triangular-det-thm\n",
    "\n",
    "Let $U$ be a triangular matrix with diagonal entries $u_{11}, u_{22}, \\dots, u_{nn}$. Then, $\\det U = u_{11}u_{22}\\dots u_{nn}$.\n",
    "\n",
    "An important consequence of this fact is that a triangular matrix $\\det U = 0$ if and only if it has a zero on its diagonal. This makes sense, and mirrors the intuition that a triangular matrix with a zero on its diagonal cannot have $n$ pivots.\n",
    ":::\n",
    "\n",
    "To prove this theorem, start by proving it for just upper triangular matrices $U$ with all nonzero pivots. Try to come up with a series of row addition operations to reduce $U$ to diagonal form, and then apply multilinearity to easily find the determinant of a diagonal matrix!\n",
    "\n",
    "The case where $U$ has a zero on its diagonal is trickier. One way is to show that you can come up with a series of row addition and column scaling operations to reduce $U$ to a form with two identical columns, then apply the alternating property of the determinant to prove that $U$ must have zero determinant!\n",
    "\n",
    "Next, we'll state and prove the key property of the determinant used for computing eigenvalues.\n",
    "\n",
    ":::{prf:theorem} Determinant of a singular and nonsingular matrix \n",
    ":label: singular-det-thm\n",
    "\n",
    "The $\\det A = 0$ if and only if $A$ is singular.\n",
    ":::\n",
    "\n",
    "To prove this statement, we'll use the [row echelon form](#row_echelon) of a matrix, in combination with our result on triangular matrices (recall that any matrix can be written as a product of elementary matrices followed by a matrix in row echelon form):\n",
    "\n",
    "* If $A$ is singular, then its row echelon form will have a zero on its diagonal. By our result on triangular matices, this implies that $\\det A  = 0$ (since row echelon matrices are triangular).\n",
    "\n",
    "* If $A$ is nonsingular, then its row echelon will have $n$ nonzero pivots (which must be diagonal elements). By our result on triangular matrices, and the fact that the product of nonzero numbers is nonzero, this implies that $\\det A \\neq 0$.\n",
    "\n",
    "Next, we'll prove another extremely important property of determinants!\n",
    "\n",
    ":::{prf:theorem} Determinant of a product\n",
    ":label: product-det-thm\n",
    "\n",
    "For compatible square matrices $A$ and $B$, $\\det AB = \\det A \\det B$.\n",
    ":::\n",
    "\n",
    "First, we'll prove that this holds for invertible matrices. To prove this, recall that any *invertible* square matrix can be factored as a product of elementary matrices:\n",
    "\n",
    "\\begin{align*}\n",
    "    A &= E_1E_2 \\dots E_m\\\\\n",
    "    B &= F_1F_2\\dots F_n\n",
    "\\end{align*}\n",
    "\n",
    "Then, we can cleverly use our knowledge of how elementary operations change the determinant:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\det AB &= \\det (E_1E_2 \\dots E_mF_1F_2\\dots F_n) \\\\\n",
    "    &= \\det E_1 \\det E_2 \\dots \\det E_m \\det F_1 \\det F_2 \\dots F_n\\\\\n",
    "    &= \\det (E_1 E_2 \\dots E_m) \\det (F_1 F_2 \\dots F_n)\\\\\n",
    "    &= \\det A \\det B\n",
    "\\end{align*}\n",
    "\n",
    "Next, we'll consider the case where $A$ or $B$, or both, is noninvertible. In this case, the result follows easily because a matrix product with a noninvertible factor is also noninvertible, and thus has zero determinant.\n",
    "\n",
    ":::{prf:theorem} Determinant of a transpose\n",
    ":label: transpose-det-thm\n",
    "\n",
    "Transposition preserves determinants, i.e., $\\det A = \\det A^{\\top}$.\n",
    ":::\n",
    "\n",
    "Try to prove this yourself! As a start, observe from the [determinants of elementary matrices](#elementary-det-thm) that transposing an *elementary matrix* does not change its determinant. Then, just like we did for matrix products, either write $A$ and $A^\\top$ as products of elementary matrices or show that $A$ is noninvertible.\n",
    "\n",
    ":::{prf:theorem} Determinant of an inverse\n",
    ":label: inverse-det-thm\n",
    "\n",
    "Let $A$ be square and nonsingular. Then, $\\det A^{-1} = \\frac {1}{\\det A}$.\n",
    ":::\n",
    "\n",
    "To prove this, start from the condition that $AA^{-1} = I$, then apply [this theorem](#product-det-thm)!\n",
    "\n",
    "## Optional: Methods of Computing the Determinant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/nikolaimatni/ese-2030/HEAD?labpath=/03_Orthogonality/053-orthogonal_matrices.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
