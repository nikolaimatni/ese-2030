{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: 6.2 Determinants\n",
    "subject:  Determinants\n",
    "subtitle: \n",
    "short_title: 6.2 Determinants\n",
    "authors:\n",
    "  - name: Nikolai Matni\n",
    "    affiliations:\n",
    "      - Dept. of Electrical and Systems Engineering\n",
    "      - University of Pennsylvania\n",
    "    email: nmatni@seas.upenn.edu\n",
    "license: CC-BY-4.0\n",
    "keywords: Determinants\n",
    "math:\n",
    "  '\\vv': '\\mathbf{#1}'\n",
    "  '\\bm': '\\begin{bmatrix}'\n",
    "  '\\em': '\\end{bmatrix}'\n",
    "  '\\R': '\\mathbb{R}'\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/nikolaimatni/ese-2030/HEAD?labpath-/05_Ch_6_Eigenvalues_and_Eigenvectors/072-determinants.ipynb)\n",
    "\n",
    "{doc}`Lecture notes <../lecture_notes/Lecture 11 - Eigvenvalues and Eigenvectors part 1 (dynamical systems, determinants, basic definitions and computations).pdf>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading\n",
    "\n",
    "Material related to this page, as well as additional exercises, can be found in ALA 1.9.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this page, you should know:\n",
    "- some key facts of the determinant,\n",
    "- several ways to find the determinant of a matrix,\n",
    "- (optional) the formal definition of a determinant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determinants\n",
    "\n",
    "We assume that you have already seen determinants in Math 1410, and focus here on reviewing the  key properties. Before proceeding, we pause to note that determinants have very deep meanings, especially in differential calculus, as they keep track of volumes as they are transformed via (linear or otherwise) functions. They are indeed very useful theoretical tools, but much like matrix inverses, are rarely computed by hand, except for $2 \\times 2$ cases. Below is a helpful link if you need a refresher on the determinant.\n",
    "\n",
    "* [Math 1410 video lecture (geometric interpretation of the determinant for small matrices)](https://www.youtube.com/watch?v=6hXxrbnbtC4)\n",
    "\n",
    "## Key Properties of the Determinant\n",
    "\n",
    "First, we'll state a couple of key facts about the determinant.\n",
    "\n",
    "\n",
    ":::{prf:definition} Key Properties of the Determinant\n",
    ":label: determinant-properties-defn\n",
    "\n",
    "1. The determinant of a matrix $A$, written $\\det A$ or $|A|$, is only defined if $A$ is square.\n",
    "\n",
    "2. The determinant of a $1\\times 1$ matirx $A = [a]$ is $\\det [a] = a$. The determinant of a $2 \\times 2$ matrix is $\\det \\bm a & b\\\\ c & d \\em= ad - bc$. You may recognize this expression from our formula for the inverse of a $2\\times 2$ matrix:\n",
    "\\begin{align*}\n",
    "\\bm a & b\\\\c&d \\em^{-1} = \\frac{1}{ad -bc}\\bm d&-b\\\\-c&a \\em.\n",
    "\\end{align*}\n",
    "\n",
    "In this case, $\\bm a & b\\\\c&d \\em^{-1}$ exists if and only if $\\det \\bm a & b\\\\c&d \\em = ad - bc \\neq 0$. This observation is true in general:\n",
    "\n",
    "3. $A^{-1}$ exists, i.e., $A$ is nonsingular, if and only if, $\\det A \\neq 0$.\n",
    "\n",
    "A corollary of Fact 3, which we will use in our eigenvalue computations, is that $A$ is singular if and only if $\\det A = 0$.\n",
    "\n",
    "4. If $U$ is a block upper diagonal matrix, i.e., if $U = \\bm U_{11} & U_{12} \\\\ 0 & U_{22}\\em$ for $U_{ij}$ of compatible dimension, then $\\det U = \\det{U_{11}} \\cdot\\det{U_{22}}$, i.e., the determinant of $U$ is given by the products of the determinants of its block diagonals.\n",
    "\n",
    "5. The determinant of a matrix is equal to the determinant of its transpose, $\\det A = \\det A^\\top$.\n",
    "\n",
    ":::\n",
    "\n",
    "These facts are all we need for now to get started finding eigenvalues.\n",
    "\n",
    "## Optional: An Algebraic Definition of the Determinant\n",
    "\n",
    "Other than for computing eigenvalues, we don't really spend much time working with determinants in this course. However, for interested students, we will give an algebraic definition of the determinant as well as some methods of finding the determinant of a matrix. This definition is taken from [these notes](https://public.websites.umich.edu/~willdana/Determinant%20Notes.pdf), which explain the connection between the geometric and algebraic interpretations of the determinant.\n",
    "\n",
    ":::{prf:definition} The Determinant of a Matrix\n",
    ":label: determinant-defn\n",
    "\n",
    "The determinant is the unique alternating, multilinear map $\\det : \\mathbb{R}^n \\to\\mathbb R$ defined on the columns of a matrix which is equal to $1$ when given the standard basis vectors in order. The determinant of a matrix $A$ with columns $a_1, a_2, \\dots, a_n$ is denoted as $|A| = \\det A = \\det(a_1, a_2, \\dots, a_n)$.\n",
    "\n",
    "* A *multilinear* function is a function which, when keeping all of the arguments except one constant, is linear in the last argument, i.e., \n",
    "\n",
    "\\begin{align*}\n",
    "&\\det(\\vv a_1, \\dots, \\vv a_{i - 1}, \\vv a_i + \\vv b_i, \\vv a_{i + 1}, \\dots, \\vv a_n) \\\\\n",
    "&= \\det(\\vv a_1, \\dots, \\vv a_{i - 1}, \\vv a_i, \\vv a_{i + 1}, \\dots, \\vv a_n) + \\det(\\vv a_1, \\dots, \\vv a_{i - 1}, \\vv b_i, \\vv a_{i + 1}, \\dots, \\vv a_n)\n",
    "\\end{align*}\n",
    "\n",
    "(A familiar special case of multilinearity is bilinearity, which is satisfied by [inner products](#inner_defn).)\n",
    "\n",
    "* An *alternating* function is a function whose output is negated after swapping two of its arguments, i.e.,\n",
    "\n",
    "\\begin{align*}\n",
    "&\\det(\\vv a_1, \\dots, \\vv a_{i}, \\dots, \\vv a_{j}, \\dots, \\vv a_n) \\\\\n",
    "&= -\\det(\\vv a_1, \\dots, \\vv a_{j}, \\dots, \\vv a_{i}, \\dots, \\vv a_n)\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "* The last condition, that the determinant is equal to $1$ when given the standard basis vectors in order, is equivalent to the statement\n",
    "\n",
    "\\begin{align*}\n",
    "\\det I = 1\n",
    "\\end{align*}\n",
    "\n",
    "where $I$ is the identity matrix.\n",
    "\n",
    "* Finally, these properties uniquely define the determinant; any function satisfying the above 3 properties must be the determinant function.\n",
    ":::\n",
    "\n",
    "From this definition, we can compute the determinants of the elementary matrices!\n",
    "\n",
    ":::{prf:theorem} Determinants of elementary matrices\n",
    ":label: elementary-det-thm\n",
    "\n",
    "Recall the three types of [elementary matrices](#elementary), corresponding to row addition, row swapping, and row scaling. The determinants of these elementary matrices are as follows:\n",
    "\n",
    "* The determinant of an elementary matrix corresponding to a row addition (e.g., $\\bm 1&0&0\\\\2&1&0\\\\0&0&1\\em$, which adds $2$ times the first row to the second) is $1$. \n",
    "\n",
    "* The determinant of an elementary matrix corresponding to switching two rows (e.g., $\\bm 1&0&0\\\\0&0&1\\\\0&1&0\\em$) is $-1$.\n",
    "\n",
    "* The determinant of an elementary matrix corresponding to scaling a row by a factor of $c$ (e.g., $\\bm 3&0&0\\\\0&1&0\\\\0&0&1\\em$) is $c$. \n",
    ":::\n",
    "\n",
    "To see why, note that the determinants of scaling and switching follow immediately from the multilinear and alternating properties of the determinant, respectively. To prove that the determinant of a row addition matrix is $1$, we'll show this is the case for a specific elementary matrix, and then you should convince yourself this is true for all row addition matrices:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\det \\bm 1&0&0\\\\2&1&0\\\\0&0&1\\em &= \\det \\bm 1&0&0\\\\0&1&0\\\\0&0&1\\em + \\det \\bm 0&0&0\\\\2&1&0\\\\0&0&1\\em \\quad\\text{(multilinearity)}\\\\\n",
    "    &= 1 + \\bm 0&0&0\\\\2&1&0\\\\0&0&1\\em  \\quad\\text{(determinant of identity is $1$)}\\\\\n",
    "    &= 1 + 2\\bm 0&0&0\\\\1&1&0\\\\0&0&1\\em  \\quad\\text{(multilinearity)}\\\\\n",
    "\\end{align*}\n",
    "\n",
    "Using the alternating property, you can show that $\\det \\bm 0&0&0\\\\1&1&0\\\\0&0&1\\em = 0$. Therefore, we have that $\\det \\bm 1&0&0\\\\2&1&0\\\\0&0&1\\em = 1$.\n",
    "\n",
    "Equipped with these results, we can see how right multiplying by an elementary matrix changes the determinant. Recall that right multiplication by an elementary matrix defines a column operation; we'll also extend these results to left multiplication by an elementary matrix (which defines a row operation).\n",
    "\n",
    ":::{prf:theorem} Determinant after an elementary operation\n",
    ":label: elementary-op-det-thm\n",
    "\n",
    "Let $E_1, E_2, E_3$ be elementary matrices corresponding to addition, swapping, and scaling, respectively. Then, for any square matrix $A$:\n",
    "\n",
    "* Right multiplication by $E_1$ preserves the determinant: $\\det AE_1 = \\det A$.\n",
    "\n",
    "* Right multiplication by $E_2$ negates the determinant: $\\det AE_2 = -\\det A$. \n",
    "\n",
    "* Right multiplication by $E_3$ (where $E_3$ scales by a factor of $c$) scales the determinant: $\\det AE_1 = c \\det A $. \n",
    "\n",
    "In particular, we are beginning to work towards one of the most important properties of the determinant. For now, note that $\\det AE = \\det A \\det E$ for any elementary matrix $E$! In fact, we can immediately use this result, and the commutativity of multiplication, to show that:\n",
    "\n",
    "\\begin{align*}\n",
    "\\det AE = \\det A \\det E = \\det E \\det A = \\det EA\n",
    "\\end{align*}\n",
    "\n",
    "In other words:\n",
    "\n",
    "* Left multiplication by $E_1$ preserves the determinant: $\\det AE_1 = \\det A$.\n",
    "\n",
    "* Left multiplication by $E_2$ negates the determinant: $\\det AE_2 = -\\det A$. \n",
    "\n",
    "* Left multiplication by $E_3$ (where $E_3$ scales by a factor of $c$) scales the determinant: $\\det AE_1 = c \\det A $. \n",
    "\n",
    "So we've characterized how elementary row and column operations affect the determinant!\n",
    ":::\n",
    "\n",
    "The proof of these properties is not hard, and follows from a few applications of the defining properties of the determinant. Try to prove these yourself! \n",
    "\n",
    "Now, we are ready to prove a lot of useful facts about determinants! We'll state and prove them one by one.\n",
    "\n",
    ":::{prf:theorem} Determinant of a triangular matrix\n",
    ":label: triangular-det-thm\n",
    "\n",
    "Let $U$ be a triangular matrix with diagonal entries $u_{11}, u_{22}, \\dots, u_{nn}$. Then, $\\det U = u_{11}u_{22}\\dots u_{nn}$.\n",
    "\n",
    "An important consequence of this fact is that a triangular matrix $\\det U = 0$ if and only if it has a zero on its diagonal. This makes sense, and mirrors the intuition that a triangular matrix with a zero on its diagonal cannot have $n$ pivots.\n",
    ":::\n",
    "\n",
    "To prove this theorem, start by proving it for just upper triangular matrices $U$ with all nonzero pivots. Try to come up with a series of row addition operations to reduce $U$ to diagonal form, and then apply multilinearity to easily find the determinant of a diagonal matrix!\n",
    "\n",
    "The case where $U$ has a zero on its diagonal is trickier. One way is to show that you can come up with a series of row addition and column scaling operations to reduce $U$ to a form with two identical columns, then apply the alternating property of the determinant to prove that $U$ must have zero determinant!\n",
    "\n",
    "Next, we'll state and prove the key property of the determinant used for computing eigenvalues.\n",
    "\n",
    ":::{prf:theorem} Determinant of a singular and nonsingular matrix \n",
    ":label: singular-det-thm\n",
    "\n",
    "The $\\det A = 0$ if and only if $A$ is singular.\n",
    ":::\n",
    "\n",
    "To prove this statement, we'll use the [row echelon form](#row_echelon) of a matrix, in combination with our result on triangular matrices (recall that any matrix can be written as a product of elementary matrices followed by a matrix in row echelon form):\n",
    "\n",
    "* If $A$ is singular, then its row echelon form will have a zero on its diagonal. By our result on triangular matices, this implies that $\\det A  = 0$ (since row echelon matrices are triangular).\n",
    "\n",
    "* If $A$ is nonsingular, then its row echelon will have $n$ nonzero pivots (which must be diagonal elements). By our result on triangular matrices, and the fact that the product of nonzero numbers is nonzero, this implies that $\\det A \\neq 0$.\n",
    "\n",
    "Next, we'll prove another extremely important property of determinants!\n",
    "\n",
    ":::{prf:theorem} Determinant of a product\n",
    ":label: product-det-thm\n",
    "\n",
    "For compatible square matrices $A$ and $B$, $\\det AB = \\det A \\det B$.\n",
    ":::\n",
    "\n",
    "First, we'll prove that this holds for invertible matrices. To prove this, recall that any *invertible* square matrix can be factored as a product of elementary matrices:\n",
    "\n",
    "\\begin{align*}\n",
    "    A &= E_1E_2 \\dots E_m\\\\\n",
    "    B &= F_1F_2\\dots F_n\n",
    "\\end{align*}\n",
    "\n",
    "Then, we can cleverly use our knowledge of how elementary operations change the determinant:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\det AB &= \\det (E_1E_2 \\dots E_mF_1F_2\\dots F_n) \\\\\n",
    "    &= \\det E_1 \\det E_2 \\dots \\det E_m \\det F_1 \\det F_2 \\dots F_n\\\\\n",
    "    &= \\det (E_1 E_2 \\dots E_m) \\det (F_1 F_2 \\dots F_n)\\\\\n",
    "    &= \\det A \\det B\n",
    "\\end{align*}\n",
    "\n",
    "Next, we'll consider the case where $A$ or $B$, or both, is noninvertible. In this case, the result follows easily because a matrix product with a noninvertible factor is also noninvertible, and thus has zero determinant.\n",
    "\n",
    ":::{prf:theorem} Determinant of a transpose\n",
    ":label: transpose-det-thm\n",
    "\n",
    "Transposition preserves determinants, i.e., $\\det A = \\det A^{\\top}$.\n",
    ":::\n",
    "\n",
    "Try to prove this yourself! As a start, observe from the [determinants of elementary matrices](#elementary-det-thm) that transposing an *elementary matrix* does not change its determinant. Then, just like we did for matrix products, either write $A$ and $A^\\top$ as products of elementary matrices or show that $A$ is noninvertible.\n",
    "\n",
    ":::{prf:theorem} Determinant of an inverse\n",
    ":label: inverse-det-thm\n",
    "\n",
    "Let $A$ be square and nonsingular. Then, $\\det A^{-1} = \\frac {1}{\\det A}$.\n",
    ":::\n",
    "\n",
    "To prove this, start from the condition that $AA^{-1} = I$, then apply [this theorem](#product-det-thm)!\n",
    "\n",
    ":::{prf:theorem} Determinant of a orthogonal matrix\n",
    ":label: orthogonal-det-thm\n",
    "\n",
    "Let $A$ be orthogonal, i.e., $AA^\\top = I$. Then, $\\det A$ is $1$ or $-1$.\n",
    ":::\n",
    "\n",
    "Try to prove this yourself using the properties we have already proven!\n",
    "\n",
    "## Optional: Methods of Computing the Determinant\n",
    "\n",
    "In the section, we will review/introduce two way of computing the determinant: the Laplace expansion and the PLU-factorization. \n",
    "\n",
    ":::{prf:definition} The Laplace Expansion\n",
    ":label: laplace-expansion-defn\n",
    "\n",
    "The Laplace expansion is a recursive definition of the determinant of an $n\\times n$ matrix in terms of the weighted sums of determinants of $(n - 1) \\times (n - 1)$ matrices, and can be derived from our characterization of the determinant of an alternating multilinear map.\n",
    "\n",
    "More specifically, to find the determinant of an $n\\times n$ matrix $A$, we choose any arbitrary row $i$ (or arbitrary column $j$) and write the *Laplace expansion along row $i$*:\n",
    "\n",
    "\\begin{align*}\n",
    "\\det A = \\sum_{j = 1}^{n}{(-1)^{i + j}}a_{ij}m_{ij}\n",
    "\\end{align*}\n",
    "\n",
    "The base case of this recursive relationship is that the determinant of any $1\\times 1$ matrix $\\bm s \\em$ is just $s$.\n",
    "\n",
    "Here, $a_{ij}$ is the element at row $i$ and column $j$ of $A$; $m_{ij}$ is the *minor* at row $i$ and column $j$, and is equal to the determinant of the $(n-1)\\times (n - 1)$ submatrix of $A$ obtained by deleting row $i$ and column $j$.\n",
    ":::\n",
    "\n",
    "This is quite an abstract definition, so let's see it at work!\n",
    "\n",
    ":::{prf:example} Finding the determinant of a $3\\times 3$ matrix \n",
    ":label: laplace-expansion-ex\n",
    "\n",
    "Consider the $3\\times 3$ matrix $A = \\bm 1&2&3\\\\4&5&6\\\\7&8&9\\em$. Applying the laplace expansion along row 1, and then using the $2\\times 2$ formula for determinants, we have:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\left| \\bm 1&2&3\\\\4&5&6\\\\7&8&9\\em \\right| &= (1) \\left| \\bm 5&6\\\\8&9\\em \\right| - (2) \\left| \\bm 4&6\\\\7&9\\em \\right| + (3)\\left| \\bm 4&5\\\\7&8\\em \\right|\\\\\n",
    "    &= (1) (45 - 48) - (2) (36 - 42) + (3)(32 - 35)\\\\\n",
    "     &= 0\n",
    "\\end{align*}\n",
    ":::\n",
    "\n",
    "Note that in the Laplace expansion, the row or column chosen to compute the expansion is arbitrary! Thus, it makes sense to expand along rows and columns with lots of zeros; if the coefficient multiplying a submatrix determinant is zero, then we don't have to actually compute that submatrix determinant!\n",
    "\n",
    "For small matrices, the Laplace expansion works fine. However, for larger matrices (even with $n \\geq 10$), this method of naively applying the Laplace will require a HUGE number of addition and multiplication operations (on the order of $n!$, or $n$ factorial)!\n",
    "\n",
    "However, by applying our [results for triangular matrices](#triangular-det-thm), we can come up with a much more computationally efficient method for computing the determinant.\n",
    "\n",
    ":::{prf:definition} The LU Method for Determinants\n",
    ":label: lu-method-defn\n",
    "\n",
    "Recall that every nonsingular matrix $A$ admits a PLU-factorization $A = PLU$. By the determinant rule for products, we can find:\n",
    "\n",
    "\\begin{align*}\n",
    "\\det A = \\det P \\det L \\det U\n",
    "\\end{align*}\n",
    "\n",
    "Note that $\\det L$ and $\\det U$ are easy to compute, just take the products of their diagonal elements. Furthemore, it is easy to compute the determinant of $P$, a permutation matrix, is significantly easier than with the Laplace expansion than for a general matrix (since most of the entries of $P$ are zeros).\n",
    ":::\n",
    "\n",
    "#### Python Break!\n",
    "\n",
    "Below are 3 code snippets demonstrating a few ways to compute the determinant. First, we run an implementation of the Laplace expansion (taken from [this article](#https://en.wikipedia.org/wiki/Laplace_expansion#Computational_expense)). Second, we implement a determinant function based on the PLU factorization. Finally, we show how to use the built in determinant function from the `scipy.linalg` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determinant (for 9x9): -0.007502281817950991\n",
      "Elapsed time (for 9x9): 4.375511169433594 seconds\n",
      "Determinant (for 10x10): -0.0334246928386742\n",
      "Elapsed time (for 10x10): 40.4918212890625 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg\n",
    "import time\n",
    "\n",
    "np.random.seed(2030)\n",
    "\n",
    "# This code is from https://en.wikipedia.org/wiki/Laplace_expansion#Computational_expense\n",
    "def laplace_det(M):\n",
    "    # Base case of recursive function: 1x1 matrix\n",
    "    if M.shape[0] == 1: \n",
    "        return M[0, 0]\n",
    "\n",
    "    total = 0\n",
    "    for column, element in enumerate(M[0]):\n",
    "        # Exclude first row and current column.\n",
    "        K = np.stack([np.concatenate((x[:column], x[column + 1 :]), axis=0) for x in M[1:]], axis=1)\n",
    "        s = 1 if column % 2 == 0 else -1 \n",
    "        total += s * element * laplace_det(K)\n",
    "    return total\n",
    "\n",
    "# Generate a random matrix\n",
    "A = np.random.rand(9, 9) \n",
    "B = np.random.rand(10, 10)\n",
    "\n",
    "# Find the determinant of A and B using Laplace expansion; also time how long it takes\n",
    "start_time_A = time.time()\n",
    "det_A = laplace_det(A)\n",
    "end_time_A = time.time()\n",
    "\n",
    "start_time_B = time.time()\n",
    "det_B = laplace_det(B)\n",
    "end_time_B = time.time()\n",
    "\n",
    "print(f\"Determinant (for 9x9): {det_A}\")\n",
    "print(f\"Elapsed time (for 9x9): {end_time_A - start_time_A} seconds\")\n",
    "print(f\"Determinant (for 10x10): {det_B}\")\n",
    "print(f\"Elapsed time (for 10x10): {end_time_B - start_time_B} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is a recursive implementation of the Laplace expansion. As you can see, this implementation isn't very fast! On this specific machine, it took ~4s to find the determinant for a $9\\times 9$ matrix; and ~40s to find the determinant for a $10\\times 10$ matrix! \n",
    "\n",
    "For anything longer, this implementation will take forever to finish. Luckily, using our linear algebra knowledge, we can give a much more efficient implementation of the determinant!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determinant (for 9x9): -0.007502281817951028\n",
      "Elapsed time (for 9x9): 0.0 seconds\n",
      "Determinant (for 10x10): -0.033424692838674074\n",
      "Elapsed time (for 10x10): 0.0 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg\n",
    "import time\n",
    "\n",
    "np.random.seed(2030)\n",
    "\n",
    "def sign(P):\n",
    "    sign = 1\n",
    "    visited = [0 for _ in range(len(P))]\n",
    "    for i in range(len(P)):\n",
    "        if visited[i] == 1:\n",
    "            continue\n",
    "        if P[i] == i:\n",
    "            continue\n",
    "        curr = P[i]\n",
    "        visited[curr] = 1\n",
    "        cycle_length = 1\n",
    "        while curr != i:\n",
    "            curr = P[curr]\n",
    "            visited[curr] = 1\n",
    "            cycle_length += 1\n",
    "        if cycle_length % 2 == 0:\n",
    "            sign = -sign\n",
    "    return sign\n",
    "\n",
    "def plu_det(M):\n",
    "    P, L, U = linalg.lu(M, p_indices=True)\n",
    "    return sign(P) * np.prod(np.diag(L)) * np.prod(np.diag(U))\n",
    "\n",
    "# Generate a random matrix\n",
    "A = np.random.rand(9, 9) \n",
    "B = np.random.rand(10, 10)\n",
    "\n",
    "# Find the determinant of A and B using Laplace expansion; also time how long it takes\n",
    "start_time_A = time.time()\n",
    "det_A = plu_det(A)\n",
    "end_time_A = time.time()\n",
    "\n",
    "start_time_B = time.time()\n",
    "det_B = plu_det(B)\n",
    "end_time_B = time.time()\n",
    "\n",
    "print(f\"Determinant (for 9x9): {det_A}\")\n",
    "print(f\"Elapsed time (for 9x9): {end_time_A - start_time_A} seconds\")\n",
    "print(f\"Determinant (for 10x10): {det_B}\")\n",
    "print(f\"Elapsed time (for 10x10): {end_time_B - start_time_B} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, with the PLU method, this method is much quicker; as you can see, for smaller matrices it was near instantaneous. A few notes; to find the PLU decomposition of $A$, we used the `scipy.linalg.lu` function, which returns the $L$ and $U$ matrices, as well as either the $P$ matrix or its [representation in one-line notation](#https://en.wikipedia.org/wiki/Permutation#One-line_notation) (this is because permutation matrices are mostly zeros, and can be encoded as just a list of numbers). Also, note the `sign` function we defined; the details aren't important, but this function is essentially a fast way to compute the determinant of a permutation matrix given in one-line notation.\n",
    "\n",
    "Finally, let's see how to use the built in functions from `scipy.linalg` (or `numpy.linalg`) to find determinants!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determinant (for 9x9): -0.007502281817951028\n",
      "Elapsed time (for 9x9): 0.0 seconds\n",
      "Determinant (for 10x10): -0.033424692838674094\n",
      "Elapsed time (for 10x10): 0.0 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg\n",
    "import time\n",
    "\n",
    "np.random.seed(2030)\n",
    "\n",
    "# Generate a random matrix\n",
    "A = np.random.rand(9, 9) \n",
    "B = np.random.rand(10, 10)\n",
    "\n",
    "# Find the determinant of A and B using Laplace expansion; also time how long it takes\n",
    "start_time_A = time.time()\n",
    "det_A = linalg.det(A)\n",
    "end_time_A = time.time()\n",
    "\n",
    "start_time_B = time.time()\n",
    "det_B = linalg.det(B)\n",
    "end_time_B = time.time()\n",
    "\n",
    "print(f\"Determinant (for 9x9): {det_A}\")\n",
    "print(f\"Elapsed time (for 9x9): {end_time_A - start_time_A} seconds\")\n",
    "print(f\"Determinant (for 10x10): {det_B}\")\n",
    "print(f\"Elapsed time (for 10x10): {end_time_B - start_time_B} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/nikolaimatni/ese-2030/HEAD?labpath=/03_Orthogonality/053-orthogonal_matrices.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it's really easy, just a single call to the `scipy.linalg.det` function!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
