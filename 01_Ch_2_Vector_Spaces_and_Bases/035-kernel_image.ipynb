{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd7554ca-5ac4-4958-b713-648e3fd54114",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "---\n",
    "title: 2.5 Kernel and Image\n",
    "subject: Vector Spaces and Bases\n",
    "subtitle: For our next trick, we'll make this vector disappear\n",
    "short_title: 2.5 Kernel and Image\n",
    "authors:\n",
    "  - name: Nikolai Matni\n",
    "    affiliations:\n",
    "      - Dept. of Electrical and Systems Engineering\n",
    "      - University of Pennsylvania\n",
    "    email: nmatni@seas.upenn.edu\n",
    "license: CC-BY-4.0\n",
    "keywords: null spaces, column spaces, solution of linear systems, superposition principle\n",
    "math:\n",
    "  '\\vv': '\\mathbf{#1}'\n",
    "  '\\bm': '\\begin{bmatrix}'\n",
    "  '\\em': '\\end{bmatrix}'\n",
    "  '\\R': '\\mathbb{R}'\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18580bf2-4547-4ee9-bdfb-981c7535bc6c",
   "metadata": {},
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/nikolaimatni/ese-2030/HEAD?labpath=/01_Vector_Spaces_and_Bases/035-kernel_image.ipynb)\n",
    "\n",
    "{doc}`Lecture notes <../lecture_notes/Lecture 04 - The Fundamental Matrix Subspaces (Kernel, Image, CoKernel, CoImage), Fundamental Theorem of Linear Algebra, and a brief interlude on the Matrix Transpose.pdf>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46f522d-2995-412b-92cf-9ff085526b18",
   "metadata": {},
   "source": [
    "## Reading\n",
    "\n",
    "Material related to this page, as well as additional exercises, can be found in ALA Ch. 2.5 and LAA 4.2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d276bcc3-237d-4cda-8bf0-39285b0a09f3",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "By the end of this page, you should know:\n",
    "- what is a kernel (null space) and image (column space) of a matrix\n",
    "- how does null space and column space relate to solutions of linear systems\n",
    "- to apply the superposition principle for solving linear systems with different right-hand vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b52c01-f3b4-4b43-baeb-f97bc73802a8",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The following two subspaces of $\\mathbb{R}^n$ (or generic vector spaces $V$) typically arise in applications of linear algebra and are closely related to systems of linear equations.\n",
    "\n",
    "1. **Null space**: set of all solutions to a system of linear equations of the form $A \\vv x = \\vv 0$. called a _homogeneous_ linear system.\n",
    "2. span of certain specified vectors. One common example is the **column space** of a matrix $A$, which will be detailed in this page. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95553d95-0888-448b-a55f-3147b14b90c4",
   "metadata": {},
   "source": [
    "## Null Space of a Matrix\n",
    "\n",
    "\n",
    ":::{prf:definition} Null space\n",
    ":label: null_defn\n",
    "The _Null space_ of a matrix $A \\in \\mathbb{R}^{m \\times n}$ is the subspace Null$A \\subset \\mathbb{R}^n$ consisting of all vectors that are annihilated by $A$:\n",
    "\\begin{equation}\n",
    "\\label{null_eqn}\n",
    "\\textrm{Null}(A) = \\{ \\vv x \\in \\mathbb{R}^n \\ | \\ A \\vv x = \\vv 0 \\} \\subset \\mathbb{R}^n.\n",
    "\\end{equation}\n",
    ":::\n",
    "\n",
    "If we think of the function $f(\\vv x) = A \\vv x$ that maps $\\vv x \\mapsto A \\vv x$, then Null$(A)$ is the subset of $\\mathbb{R}^n$ that $f(\\vv x)$ to $\\vv 0$.\n",
    "```{note}\n",
    "The _Null space_ is also known as the _kernel_ of the matrix. We will use Null$(A)$ in our notes even though ALA uses _kernel_, because _null space_ is more descriptive of what it actually is: $\\{ \\vv x \\in \\mathbb{R}^n \\ | \\ A \\vv x = \\vv 0 \\}$. \n",
    "```\n",
    "\n",
    ":::{prf:example}\n",
    ":label:null_eg\n",
    "\n",
    "Consider the following system of homogeneous equations\n",
    "\\begin{equation}\n",
    "\\label{null_eg_eqn}\n",
    "x_1 + 2x_2 + x_3 &= 0, \\\\\n",
    "-x_1 + 4x_2 + 2x_3 &= 0, \n",
    "\\end{equation}\n",
    "or in matrix form $A \\vv x = \\vv 0$, where $A = \\bm1 & 2 & 1 \\\\ -1 & 4 & 2 \\em$.\n",
    "The set of $\\vv x$ satisfying $A \\vv x = \\vv 0$ is the [solution set](../Linear_Algebraic_Systems/026-linsys-general.ipynb#solution_set) of [](#null_eg_eqn). Our goal is to relate the solution set to the matrix $A$ which will give us a geometric interpretation. \n",
    "\n",
    "Is $\\vv u = \\bm 0 \\\\ 1 \\\\ -2 \\em$ in Null$(A)$? \n",
    "\n",
    "Evaluating $A \\vv u = \\bm1 & 2 & 1 \\\\ -1 & 4 & 2 \\em\\bm 0 \\\\ 1 \\\\ -2 \\em = \\bm 0 \\\\ 0\\em \\Rightarrow A \\vv u = \\vv 0 \\Rightarrow \\vv u \\in $Null$(A)$. \n",
    ":::\n",
    "\n",
    "We call Null$(A)$ the null _space_ because Null$(A)$ is a [subspace](./032-subspaces.ipynb#sub_def) and we test it as follows. Suppose $\\vv u, \\vv v \\in $Null$(A)$ and $c d \\in \\mathbb{R}$. We need to check if $c \\vv u + d \\vv v \\in$Null$(A)$. \n",
    "\\begin{equation}\n",
    "\\label{null_space_check}\n",
    "A(c \\vv u + d \\vv v) &= c A \\vv u + d A \\vv v, \\ (\\textrm{linearly of matrix multiplication}) \\\\\n",
    "&= c \\vv 0 + d \\vv 0, \\ (\\vv u, \\vv v \\in \\textrm{Null}(A)) \\\\\n",
    "&= \\vv 0\n",
    "\\end{equation}\n",
    "\n",
    "From [](#null_space_check), if $A \\in \\mathbb{R}^{m \\times n}$, then Null$(A)$ is a subspace of $\\mathbb{R}^n$ which leads ot the following principle. \n",
    "\n",
    "```{prf:theorem} Superposition principle\n",
    ":label: super_thm\n",
    "If $\\vv u_1, \\vv u_2, \\ldots, \\vv u_k$ are each solutions to $A \\vv u = 0$, then so is every [linear combination](./033-span_lin_ind.ipynb#ln_comb) $c_1 \\vv u_1 + c_2\\vv u_2 + \\ldots + c_k\\vv u_k$.\n",
    "```\n",
    "\n",
    "```{warning}\n",
    "The set of solutions to $A \\vv x = \\vv b$ where $\\vv b \\neq \\vv 0$ is not a subspace! \n",
    "```\n",
    "\n",
    "```{important}\n",
    "[Superposition](#super_thm) has the following practical implication. We only need to find a few specific solutions to $A \\vv u = 0$ to construct every possible solution via linear combinations.\n",
    "```\n",
    "\n",
    "```{note}\n",
    "The same ideas of solving linear systems with a matrix representation extend to more general linear systems with infinite dimensional vector spaces such as linear differential equations, which we will see later in the course. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f650ea-b1d6-4601-89a3-ca703fe6fd66",
   "metadata": {},
   "source": [
    "## Describing the Null Space\n",
    "\n",
    "An explicit description of Null$(A)$ can be obtained by solving $A \\vv x = 0$, for example, using Gaussian Elimination.\n",
    "\n",
    ":::{prf:example}\n",
    ":label:null_eg_GE\n",
    "Let us find a [basis](./034-basis_dim.ipynb#basis_defn) for Null$(A)$, where \n",
    "$A = \\bm -3 & 6 & -1 & 1 & -7 \\\\\n",
    "1 & -2 & 2 & 3 & -1 \\\\\n",
    "2 & -4 & 5 & 8 & -4\n",
    "\\em$. We reduce $A$ to row echelon form\n",
    "\\begin{equation}\n",
    "\\label{null_GE_eqn}\n",
    "A \\leftrightarrow \\bm 1 & -2 & 0 & -1 & 3 \\\\\n",
    "0 & 0 & 1 & 2 & -2 \\\\\n",
    "0 & 0 & 0 & 0 & 0\n",
    "\\em \\leftrightarrow x_1 = 2x_2 + x_4 - 3x_5, \\ x_3 = -2x_4 + 2x_5.\n",
    "\\end{equation}\n",
    "From [](#null_GE_eqn), the free variables are $x_2, x_4, x_4$ and the basic variables are $x_1, x_3$, since, the pivots are at $(1, 1), (2, 3)$. We can decompose the general solution as\n",
    "\\begin{equation}\n",
    "\\label{null_soln}\n",
    "\\bm x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\\\ x_5\\em = \\bm 2x_2 + x_4 - 3x_5 \\\\ x_2 \\\\ -2x_4 + 2x_5 \\\\ x_4 \\\\ x_5\\em = x_2 \\bm 2 \\\\ 1 \\\\ 0 \\\\ 0 \\\\ 0\\em + x_4 \\bm 1 \\\\ 0 \\\\ -2 \\\\ 1 \\\\ 0\\em + x_5 \\bm -3 \\\\ 0 \\\\ 2 \\\\ 0 \\\\ 1\\em = x_2 \\vv u_1 + x_4 \\vv u_2 + x_5 \\vv u_3, \\\\\n",
    "\\textrm{where}, \\vv u_1 = \\bm 2 \\\\ 1 \\\\ 0 \\\\ 0 \\\\ 0\\em, \\ \\vv u_2 = \\bm 1 \\\\ 0 \\\\ -2 \\\\ 1 \\\\ 0\\em, \\ \\vv u_3 = \\bm -3 \\\\ 0 \\\\ 2 \\\\ 0 \\\\ 1\\em.\n",
    "\\end{equation}\n",
    "From [](#null_soln), every linear combination of $\\vv u_1, \\vv u_2, \\vv u_3$ is in Null$(A)$. Also, $\\vv u_1, \\vv u_2, \\vv u_3$ are linearly independent (think when does [](#null_soln) become zero and why so?), hence, $\\vv u_1, \\vv u_2, \\vv u_3$ form a basis for Null$(A)$.\n",
    "\n",
    "We conclude that Null$(A) \\subset \\mathbb{R}^5$ is a subspace of [dimension](./034-basis_dim.ipynb#dim_defn) 3.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27d276b-42e7-4840-aeca-e48e3b24756c",
   "metadata": {},
   "source": [
    "## The Column Space of $A$\n",
    "\n",
    "We have seen previously that the matrix-vetor product $A \\vv x$, \n",
    "$$\n",
    "A \\vv x = x_1 \\vv a_1 + x \\vv a_2 + \\ldots + x_n \\vv a_n,\n",
    "$$\n",
    "is the linear combination of the columns of $A = \\bm \\vv a_1 & \\vv a_2 & \\ldots & \\vv a_n\\em$ weighted by the elements of $\\vv x$. By letting the coefficients of $\\vv x$ vary, we define the _column space_ of $A$.\n",
    "\n",
    ":::{prf:definition} Column space\n",
    "The column space of an $m \\times n$ matrix $A$, written as Col$(A)$, is the set of all linear combinations of the columns of $A =  \\bm \\vv a_1 & \\vv a_2 & \\ldots & \\vv a_n\\em$:\n",
    "\\begin{equation}\n",
    "\\label{col_eqn}\n",
    "\\textrm{Col}(A) &= \\{\\vv c \\in \\mathbb{R}^m : \\vv b = A \\vv x \\ \\textrm{for some} \\ \\vv x \\in \\mathbb{R}^n\\}, \\\\\n",
    "&= \\textrm{span}(\\vv a_1, \\vv a_2, \\ldots, \\vv a_n).\n",
    "\\end{equation}\n",
    "The Col$(A)$ is also sometimes called the _image_ or _range space_ of $A$.\n",
    ":::\n",
    "\n",
    "Since Col$(A)$ is defined by the span of some vectors, it is immediate that Col$(A)$ is a subspace. However, Col$(A) \\subset \\mathbb{R}^m$ (where $\\vv b$ lives), not $\\mathbb{R}^n$ (where Null$(A)$ and $\\vv x$ lives). \n",
    "\n",
    "```{important}\n",
    "It is immediate that $A \\vv x = \\vv b$ has at least one solution if and only if $\\vv b \\in $Col$(A)$. \n",
    "```\n",
    "\n",
    ":::{exercise}\n",
    ":label:col_ex\n",
    "Find a matrix $A$ so that the set \n",
    "\\begin{equation}\n",
    "\\label{col_ex_eqn}\n",
    "W = \\left\\{ \\bm a + b - 3c \\\\ b + c + a \\\\ -a-b - 6c \\\\ 7a + 7b + 2c\\em : a, b, c \\in \\mathbb{R}\\right\\}\n",
    "\\end{equation}\n",
    "is equal to Col$(A)$.\n",
    "\n",
    "```{solution} col_ex\n",
    ":class: dropdown \n",
    "\n",
    "First, we write $W$ as a linear combination\n",
    "\\begin{equation}\n",
    "\\label{col_ex_soln1}\n",
    "W = \\left\\{ a \\bm 1 \\\\ 1 \\\\ -1 \\\\ 7\\em + b \\bm 1 \\\\ 1 \\\\ -1 \\\\ 7\\em + c \\bm -3 \\\\ 1 \\\\ -6 \\\\ 2\\em : a, b, c \\in \\mathbb{R}\\right\\}\n",
    "\\end{equation}\n",
    "Note that in [](#col_ex_soln1), the first two vectors are the same. Hence, rewriting [](#col_ex_soln1)\n",
    "\\begin{equation}\n",
    "\\label{col_ex_soln2}\n",
    "W &= \\left\\{ (a+b) \\bm 1 \\\\ 1 \\\\ -1 \\\\ 7\\em + c \\bm -3 \\\\ 1 \\\\ -6 \\\\ 2\\em = a' \\bm 1 \\\\ 1 \\\\ -1 \\\\ 7\\em + c \\bm -3 \\\\ 1 \\\\ -6 \\\\ 2\\em : a', c \\in \\mathbb{R}\\right\\}, \\\\\n",
    "&= \\textrm{span}\\left\\{\\bm 1 \\\\ 1 \\\\ -1 \\\\ 7\\em, \\bm -3 \\\\ 1 \\\\ -6 \\\\ 2\\em\\right\\}\n",
    "\\end{equation}\n",
    "We can set the vectors in [](#col_ex_soln2) as the columns of $A: A = \\bm 1 & -3 \\\\ 1 & 1 \\\\ -1 & -6 \\\\ 7 & 2\\em \\Rightarrow W = $Col$(A)$. \n",
    "\n",
    "``` \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9143e156-534b-4edc-bc8e-49b8d9aa7fba",
   "metadata": {},
   "source": [
    "## The Complete Solution to $A \\vv x = \\vv b$\n",
    "\n",
    "```{prf:theorem}\n",
    ":label: soln_thm\n",
    "The linear system $A \\vv x = \\vv b$ has at least one solution $\\vv x^*$ if and only if $\\vv b \\in $Col$(A)$. If this occurs, then $\\vv x$ is a solution to $A \\vv x = \\vv b$ if and only if \n",
    "$$\n",
    "\\vv x = \\vv x^* + \\vv n,\n",
    "$$\n",
    "where $\\vv n \\in$ Null$(A)$ is an element of the null space of $A$.\n",
    ":::{prf:proof} Proof of [](#soln_thm)\n",
    ":label: proof-soln_thm\n",
    ":class: dropdown\n",
    "The first part of the theorem was already discussed [here](./033-span_lin_ind.ipynb#lin_dep_thm). Suppose, $\\vv x$ and $\\vv x^*$ are both solutions so that $A \\vv x = A \\vv x^* = \\vv b$, then their difference $\\vv n = \\vv x - \\vv x^*$ should satisfy\n",
    "$$\n",
    "A \\vv n = A (\\vv x - \\vv x^*) = A \\vv x - A \\vv x^* = \\vv b - \\vv b = \\vv 0\n",
    "$$\n",
    "so that $\\vv n \\in$Null$(A)$. This means that $\\vv x = \\vv x^* + (\\vv x - \\vv x^*) = \\vv x^* + \\vv n$.\n",
    ":::\n",
    "```\n",
    "\n",
    "```{note} Consequences of [](#soln_thm)\n",
    "1. [](#soln_thm) tells us that to contruct the most general solution to $A \\vv x = \\vv b$, we only need to know a _particular solution $\\vv x^*$_ and the general solution to $A \\vv n = \\vv 0$.\n",
    "2. Remember, we solve inhomogeneous linear ordinary differential equations similar to [](#soln_thm). We will see later that linear algebraic systems and linear ordinary differential equations are both examples of _general linear systems_.\n",
    "3. Computing the general solution to $A \\vv x = \\vv b$ requires applying Gaussian Elimination (GE) first to $\\bm A | \\vv b\\em$ to get a particular solution, and then GE to $\\bm A | \\vv 0 \\em$ to characterize the null space.\n",
    "```\n",
    "\n",
    ":::{exercise}\n",
    ":label:thm_ex\n",
    "\n",
    "Find all solutions to the linear system\n",
    "\n",
    "\\begin{align*}\n",
    "    x_1 + 2x_2 + x_3 - 2x_4 &= 9\\\\\n",
    "    -2x_1 - 3x_2 - x_3 + x_4 &= -7\\\\\n",
    "    x_1 + x_2 - x_3 - x_4 &= 2\n",
    "\\end{align*}\n",
    "\n",
    "```{solution} thm_ex\n",
    ":class: dropdown \n",
    "\n",
    "First, let's form the augmented matrix:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\left[ \\begin{array}{cccc|c}\n",
    "        1 & 2 & 1 & -2 & 9\\\\\n",
    "        -2 & -3 & -1 & 1 & -7\\\\\n",
    "        1 & 1 & -1 & -1 & 2\n",
    "    \\end{array} \\right]\n",
    "\\end{align*}\n",
    "\n",
    "Putting the coefficient matrix in row echelon form, we get the equivalent system\n",
    "\n",
    "\\begin{align*}\n",
    "    \\left[ \\begin{array}{cccc|c}\n",
    "        1 & 2 & 1 & -2 & 9\\\\\n",
    "        0 & 1 & 1 & -3 & 11\\\\\n",
    "        0 & 0 & -1 & -2 & 4\n",
    "    \\end{array} \\right]\n",
    "\\end{align*}\n",
    "\n",
    "Putting the coefficient matrix in reduced row echelon form (i.e., eliminating above the pivots, then scaling the pivots to equal 1), we get the equivalent system\n",
    "\n",
    "\\begin{align*}\n",
    "    \\left[ \\begin{array}{cccc|c}\n",
    "        1 & 0 & 0 & 6 & -17\\\\\n",
    "        0 & 1 & 0 & -5 & 15\\\\\n",
    "        0 & 0 & 1 & 2 & -4\n",
    "    \\end{array} \\right]\n",
    "\\end{align*}\n",
    "\n",
    "This is equivalent to the linear system\n",
    "\n",
    "\\begin{align*}\n",
    "    x_1 + 6x_4 &= -17\\\\\n",
    "    x_2 - 5x_4 &= 15\\\\\n",
    "    x_3 + 2x_4 &= -4\n",
    "\\end{align*}\n",
    "\n",
    "whose solutions are given by:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\bm x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\em &= \\bm -17 - 6x_4 \\\\ 15 + 5x_4 \\\\ -4 - 2x_4 \\\\ x_4 \\em \\\\\n",
    "    &= \\underbrace{\\bm -17 \\\\ 15 \\\\ -4 \\\\ 0 \\em}_{\\text{particular solution}} + \\underbrace{x_4 \\bm -6 \\\\ 5 \\\\ -2 \\\\1 \\em}_{\\text{null space}}\\tag{for all $x_4 \\in \\mathbb R$}\n",
    "\\end{align*}\n",
    "\n",
    "```\n",
    "\n",
    ":::\n",
    "\n",
    "```{prf:theorem} Summary\n",
    ":label: sum_thm\n",
    "If $A \\in \\mathbb{R}^{m \\times n}$, then the following conditions are equivalent (any one implies the other):\n",
    "1. Null$(A) = \\{\\vv 0\\}$, i.e., $A \\vv x = 0$ if and only if $\\vv x = 0$\n",
    "2. rank$(A) = n$\n",
    "3. The linear system $A \\vv x = \\vv b$ has no [free variables](../Linear_Algebraic_Systems/026-linsys-general.ipynb#free_basic_defn)\n",
    "4. The system $A \\vv x = \\vv b$ has a unique solution for each $\\vv b \\in $Col$(A)$.\n",
    "```\n",
    "\n",
    "We can specialize [](#sum_thm) or square matrices, which allows us to characterize if $A$ is invertible via either its null space or column space.\n",
    "\n",
    "```{prf:theorem} Invertible Matrices\n",
    ":label: inv_thm\n",
    "If $A \\in \\mathbb{R}^{n \\times n}$, then the following conditions are equivalent:\n",
    "1. $A$ is nonsingular\n",
    "2. rank$(A) = n$\n",
    "3. Null$(A) = \\{\\vv 0\\}$\n",
    "4. Col$(A) = \\mathbb{R}^n$\n",
    "5. $A \\vv x = \\vv b$ has a unique solution for all $\\vv b \\in \\mathbb{R}^n$.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2a92f5-7e45-4bd0-ad1b-a1fb9bca22f3",
   "metadata": {},
   "source": [
    "## Applying the Superposition Principle\n",
    "\n",
    "For homogeneous systems $A \\vv x = \\vv 0$, [superposition](./035-kernel_image.ipynb#super_thm) let us generate new solutions by combining known solutions. For _inhomogeneous systems_ $A \\vv x = \\vv b$, superposition lets us combine solutions for different $\\vv b$ vectors.\n",
    "\n",
    "Suppose we have solutions $\\vv x_1^*$ and $\\vv x_2^*$ to $A \\vv x = \\vv b_1$ and $A \\vv x = \\vv b_2$, respectively. Can I build a solution to $A \\vv x = c_1 \\vv b_1 + c_2 \\vv b_2$ for some $c_1, c_2 \\in \\mathbb{R}$? The answer is [superposition](./035-kernel_image.ipynb#super_thm)!  Let's try $\\vv x^* = c_1 \\vv x_1^* + c_2 \\vv x_2^*$:\n",
    "\\begin{equation}\n",
    "\\label{super_eqn}\n",
    "A \\vv x^* = A (c_1 \\vv x_1^* + c_2 \\vv x_2^*) = c_1 (A \\vv x_1^*) + c_2 (A \\vv x_2^*) = c_1 \\vv b_1 + c_2 \\vv b_2.\n",
    "\\end{equation}\n",
    "From [](#super_eqn), $\\vv x^* = c_1 \\vv x_1^* + c_2 \\vv x_2^*$ is a solution to $A \\vv x = c_1 \\vv b_1 + c_2 \\vv b_2$. \n",
    "\n",
    ":::{prf:example}\n",
    ":label:sup_eg\n",
    "\n",
    "The system\n",
    "$$\n",
    "\\bm 4 & 1 \\\\ 1 & 4 \\em \\bm x_1 \\\\ x_2 \\em = \\bm f_1 \\\\ f_2 \\em\n",
    "$$\n",
    "models the mechanical response of a pair of masses connected by springs subject to external forcing. \n",
    "\n",
    "The solution $\\vv x = \\bm x_1 \\\\ x_2 \\em$ is the displacement of the masses and the right-hand side $\\vv f = \\bm f_1 \\\\ f_2 \\em$ are the appplied forces.\n",
    "\n",
    "For $\\vv f = \\vv e_1 = \\bm 1 \\\\ 0 \\em$, $\\vv x_1^* = \\bm \\frac{4}{15} \\\\ -\\frac{1}{15}\\em$; and $\\vv f = \\vv e_2 = \\bm 0 \\\\ 1 \\em$, $\\vv x_2^* = \\bm -\\frac{1}{15} \\\\ \\frac{4}{15}\\em$. \n",
    "\n",
    "Hence, we can write the general solution for $\\vv f = \\bm f_1 \\\\ f_2 \\em f_1 \\vv e_1 + f_2 \\vv e_2$ as $\\vv x^* = f_1 \\vv x_1^* + f_2 \\vv x_2^*$.  \n",
    ":::\n",
    "\n",
    "### The General form\n",
    "\n",
    "We can generalize the above idea to more than two solutions. \n",
    "\n",
    "If $\\vv x_1^*, \\vv x_2^*, \\ldots, \\vv x_k^*$ are solutions to $A \\vv x = \\vv b_1, A \\vv x = \\vv b_2, \\ldots, A \\vv x = \\vv b_k$, then, for any choice of $c_1, c_2, \\ldots, c_k \\in \\mathbb{R}$, a particular solution to\n",
    "\\begin{equation}\n",
    "\\label{gen}\n",
    "A \\vv x = c_1 \\vv b_1 + c_2 \\vv b_2 + \\ldots + c_k \\vv b_k\n",
    "\\end{equation}\n",
    "is given by $\\vv x^* = c_1 \\vv x_1^* + c_2 \\vv x_2^* + \\ldots + c_k \\vv x_k^*$. The general solution to [](#gen) is\n",
    "\\begin{equation}\n",
    "\\label{gen_n}\n",
    "\\vv x = \\vv x^* + \\vv n = c_1 \\vv x_1^* + c_2 \\vv x_2^* + \\ldots + c_k \\vv x_k^* + \\vv n,\n",
    "\\end{equation}\n",
    "where $\\vv n \\in $Null$(A)$.\n",
    "\n",
    ":::{important}\n",
    ":label: sup_imp\n",
    "If we know the particular solutions $\\vv x_1^*, \\vv x_2^*, \\ldots, \\vv x_m^*$ to $A \\vv x = \\vv e_i$ for $i = 1, 2, \\ldots, m$, where $\\vv e_1, \\ldots, \\vv e_m$ are the standard basis vectors of $\\mathbb{R}^m$, then, we can construct a particular solution $\\vv x^*$\n",
    " to $A \\vv x = \\vv b$ by first writing \n",
    " $$\n",
    "\\vv b = b_1 \\vv e_1 + b_2 \\vv e_2  +\\ldots + b_m \\vv e_m\n",
    " $$\n",
    " to conclude that $\\vv x = b_1 \\vv x_1 + b_2 \\vv x_2  +\\ldots + b_m \\vv x_m$ is a solution to $A \\vv x = \\vv b$. This tells us how the elements $b_i$ of $\\vv b$ affect our solution $\\vv x^*$.\n",
    ":::\n",
    "\n",
    "```{note}\n",
    "If $A$ is square, then [this fact](#sup_imp) is another way of computing $A^{-1}$. The vectors $\\vv x_1^*, \\vv x_2^*, \\ldots, \\vv x_m^*$ are the columns of $A^{-1}$(what are the $m$ linear systems?), and $\\vv x^* = A^{-1}\\vv b$.\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c3cf97-b8e5-492e-8648-d7b4c141daf0",
   "metadata": {},
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/nikolaimatni/ese-2030/HEAD?labpath=/01_Vector_Spaces_and_Bases/035-kernel_image.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ece6689-96dd-40ec-b415-6b7031b90955",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
